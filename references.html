


<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!-->
<html class="no-js" lang="en">
<!--<![endif]-->

<head>
  <meta charset="utf-8">
  <meta name="generator" content="Docutils 0.19: https://docutils.sourceforge.io/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>References &mdash; Torch Uncertainty 0.1.0 documentation</title>
  

  <link rel="shortcut icon" href="_static/images/logo_torch_uncertainty.png" />
  
  

  

  
  
  

  

  <link rel="stylesheet" href="_static/css/custom.css" type="text/css" />
  <!-- <link rel="stylesheet" href="_static/pygments.css" type="text/css" /> -->
  <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="_static/css/custom.css" type="text/css" />
  <link rel="stylesheet" href="_static/copybutton.css" type="text/css" />
  <link rel="stylesheet" href="_static/sg_gallery.css" type="text/css" />
  <link rel="stylesheet" href="_static/sg_gallery-binder.css" type="text/css" />
  <link rel="stylesheet" href="_static/sg_gallery-dataframe.css" type="text/css" />
  <link rel="stylesheet" href="_static/sg_gallery-rendered-html.css" type="text/css" />
  <link rel="index" title="Index" href="genindex.html" />
  <link rel="search" title="Search" href="search.html" />
  <link rel="prev" title="Contributing" href="contributing.html" />
  <!-- Google Analytics -->
  <script type="text/javascript">
    var collapsedSections = [];
  </script>
  
  <!-- End Google Analytics -->
  

  
  <script src="_static/js/modernizr.min.js"></script>
  <script>
    MathJax = {
        chtml: {
            scale: 1,
            minScale: 1,
        },
        svg: {
            scale: 1,
            minScale: 1,
        }
    }
</script>

  <!-- Preload the theme fonts -->

<link rel="preload" href="_static/fonts/FreightSans/freight-sans-book.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="_static/fonts/FreightSans/freight-sans-medium.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="_static/fonts/IBMPlexMono/IBMPlexMono-Medium.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="_static/fonts/FreightSans/freight-sans-bold.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="_static/fonts/FreightSans/freight-sans-medium-italic.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="_static/fonts/IBMPlexMono/IBMPlexMono-SemiBold.woff2" as="font" type="font/woff2" crossorigin="anonymous">

<!-- Preload the katex fonts -->

<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Math-Italic.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Main-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Main-Bold.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size1-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size4-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size2-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size3-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Caligraphic-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
  <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.15.2/css/all.css"
    integrity="sha384-vSIIfh2YWi9wW0r9iZe7RJPrKwp6bG+s9QZMoITbCckVJqGCCRhc+ccxNcdpHuYu" crossorigin="anonymous">
</head>

<div class="container-fluid header-holder tutorials-header" id="header-holder">
  <div class="container">
    <div class="header-container">
      <a class="header-logo" href="https://torch-uncertainty.github.io/"
        aria-label="OpenMMLab"></a>

      <div class="main-menu">
        <ul>
          <li>
            <a href="https://github.com/ENSTA-U2IS/torch-uncertainty" target="_blank">GitHub</a>
          </li>
        </ul>
      </div>

      <a class="main-menu-open-button" href="#" data-behavior="open-mobile-menu"></a>
    </div>
  </div>
</div>

<body class="pytorch-body">

   

  

  <div class="table-of-contents-link-wrapper">
    <span>Table of Contents</span>
    <a href="#" class="toggle-table-of-contents" data-behavior="toggle-table-of-contents"></a>
  </div>

  <nav data-toggle="wy-nav-shift" class="pytorch-left-menu" id="pytorch-left-menu">
    <div class="pytorch-side-scroll">
      <div class="pytorch-menu pytorch-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
        <div class="pytorch-left-menu-search">
          

          
          
          
          

          



<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search Docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        
        
        
        
        
        <p class="caption" role="heading"><span class="caption-text">Contents:</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="installation.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="quickstart.html">Quickstart</a></li>
<li class="toctree-l1"><a class="reference internal" href="introduction_uncertainty.html">Introduction to Classification Uncertainty</a></li>
<li class="toctree-l1"><a class="reference internal" href="auto_tutorials/index.html">Tutorials</a></li>
<li class="toctree-l1"><a class="reference internal" href="api.html">API reference</a></li>
<li class="toctree-l1"><a class="reference internal" href="contributing.html">Contributing</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">References</a></li>
</ul>

        
        
      </div>
    </div>
  </nav>

  <div class="pytorch-container">
    <div class="pytorch-page-level-bar" id="pytorch-page-level-bar">
      <div class="pytorch-breadcrumbs-wrapper">
        















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="pytorch-breadcrumbs">
    
    <li>
      <a href="index.html">
        Docs
      </a> &gt;
    </li>

    
    <li>References</li>
    
    <!-- 
    <li class="pytorch-breadcrumbs-aside">
      
      
      
      
      
      <a href="/zh_CN//references.html" class="fa fa-language"> 以中文阅读</a>
      
      
    </li>
    
     -->
  </ul>

  
</div>
      </div>

      <div class="pytorch-shortcuts-wrapper" id="pytorch-shortcuts-wrapper">
        Shortcuts
      </div>
    </div>

    <section data-toggle="wy-nav-shift" id="pytorch-content-wrap" class="pytorch-content-wrap">
      <div class="pytorch-content-left">

        

        <div class="pytorch-call-to-action-links">
          <div id="tutorial-type">references</div>

          <!-- <div id="google-colab-link">
            <img class="call-to-action-img" src="_static/images/pytorch-colab.svg" />
            <div class="call-to-action-desktop-view">Run in Google Colab</div>
            <div class="call-to-action-mobile-view">Colab</div>
          </div> -->
          <div id="download-notebook-link">
            <img class="call-to-action-notebook-img" src="_static/images/pytorch-download.svg" />
            <div class="call-to-action-desktop-view">Download Notebook</div>
            <div class="call-to-action-mobile-view">Notebook</div>
          </div>
          <div id="github-view-link">
            <img class="call-to-action-img" src="_static/images/pytorch-github.svg" />
            <div class="call-to-action-desktop-view">View on GitHub</div>
            <div class="call-to-action-mobile-view">GitHub</div>
          </div>
        </div>

        
        
          <div class="rst-content">
            
            <div role="main" class="main-content" itemscope="itemscope" itemtype="http://schema.org/Article">
              <article itemprop="articleBody" id="pytorch-article" class="pytorch-article">
                
                
  <section id="references">
<h1>References<a class="headerlink" href="#references" title="Permalink to this heading">¶</a></h1>
<p>Please find an exhaustive list of the references of the models, metrics, and datasets used in this library through the sections below.</p>
<section id="uncertainty-models">
<h2>Uncertainty Models<a class="headerlink" href="#uncertainty-models" title="Permalink to this heading">¶</a></h2>
<p>The following uncertainty models are implemented.</p>
<section id="deep-ensembles">
<h3>Deep Ensembles<a class="headerlink" href="#deep-ensembles" title="Permalink to this heading">¶</a></h3>
<p>For Deep Ensembles, consider citing:</p>
<p><strong>Simple and Scalable Predictive Uncertainty Estimation using Deep Ensembles</strong></p>
<ul class="simple">
<li><p>Authors: <em>Balaji Lakshminarayanan, Alexander Pritzel, and Charles Blundell</em></p></li>
<li><p>Paper: <a class="reference external" href="https://arxiv.org/pdf/1612.01474.pdf">NeurIPS 2017</a>.</p></li>
</ul>
</section>
<section id="batchensemble">
<h3>BatchEnsemble<a class="headerlink" href="#batchensemble" title="Permalink to this heading">¶</a></h3>
<p>For BatchEnsemble, consider citing:</p>
<p><strong>BatchEnsemble: An alternative approach to Efficient Ensemble and Lifelong Learning</strong></p>
<ul class="simple">
<li><p>Authors: <em>Yeming Wen, Dustin Tran, and Jimmy Ba</em></p></li>
<li><p>Paper: <a class="reference external" href="https://arxiv.org/pdf/2002.06715.pdf">ICLR 2020</a>.</p></li>
</ul>
</section>
<section id="masksembles">
<h3>Masksembles<a class="headerlink" href="#masksembles" title="Permalink to this heading">¶</a></h3>
<p>For Masksembles, consider citing:</p>
<p><strong>Masksembles for Uncertainty Estimation</strong></p>
<ul class="simple">
<li><p>Authors: <em>Nikita Durasov, Timur Bagautdinov, Pierre Baque, and Pascal Fua</em></p></li>
<li><p>Paper: <a class="reference external" href="https://arxiv.org/pdf/2012.08334">CVPR 2021</a>.</p></li>
</ul>
</section>
<section id="mimo">
<h3>MIMO<a class="headerlink" href="#mimo" title="Permalink to this heading">¶</a></h3>
<p>For MIMO, consider citing:</p>
<p><strong>Training independent subnetworks for robust prediction</strong></p>
<ul class="simple">
<li><p>Authors: <em>Marton Havasi, Rodolphe Jenatton, Stanislav Fort, Jeremiah Zhe Liu, Jasper Snoek, Balaji Lakshminarayanan, Andrew M. Dai, and Dustin Tran</em></p></li>
<li><p>Paper: <a class="reference external" href="https://arxiv.org/pdf/2010.06610.pdf">ICLR 2021</a>.</p></li>
</ul>
</section>
<section id="packed-ensembles">
<h3>Packed-Ensembles<a class="headerlink" href="#packed-ensembles" title="Permalink to this heading">¶</a></h3>
<p>For Packed-Ensembles, consider citing:</p>
<p><strong>Packed-Ensembles for Efficient Uncertainty Estimation</strong></p>
<ul class="simple">
<li><p>Authors: <em>Olivier Laurent, Adrien Lafage, Enzo Tartaglione, Geoffrey Daniel, Jean-Marc Martinez, Andrei Bursuc, and Gianni Franchi</em></p></li>
<li><p>Paper: <a class="reference external" href="https://arxiv.org/abs/2210.09184">ICLR 2023</a>.</p></li>
</ul>
</section>
</section>
<section id="metrics">
<h2>Metrics<a class="headerlink" href="#metrics" title="Permalink to this heading">¶</a></h2>
<p>The following metrics are used/implemented.</p>
<section id="expected-calibration-error">
<h3>Expected Calibration Error<a class="headerlink" href="#expected-calibration-error" title="Permalink to this heading">¶</a></h3>
<p>For the expected calibration error, consider citing:</p>
<p><strong>Obtaining Well Calibrated Probabilities Using Bayesian Binning</strong></p>
<ul class="simple">
<li><p>Authors: <em>Mahdi Pakdaman Naeini, Gregory F. Cooper, and Milos Hauskrecht</em></p></li>
<li><p>Paper: <a class="reference external" href="https://www.dbmi.pitt.edu/wp-content/uploads/2022/10/Obtaining-well-calibrated-probabilities-using-Bayesian-binning.pdf">AAAI 2015</a>.</p></li>
</ul>
</section>
</section>
<section id="datasets">
<h2>Datasets<a class="headerlink" href="#datasets" title="Permalink to this heading">¶</a></h2>
<p>The following datasets are used/implemented.</p>
<section id="cifar-10-cifar-100">
<h3>CIFAR-10 &amp; CIFAR-100<a class="headerlink" href="#cifar-10-cifar-100" title="Permalink to this heading">¶</a></h3>
<p><strong>Learning multiple layers of features from tiny images</strong></p>
<ul class="simple">
<li><p>Authors: <em>Alex Krizhevsky</em></p></li>
<li><p>Paper: <a class="reference external" href="https://www.cs.toronto.edu/~kriz/learning-features-2009-TR.pdf">MIT Tech Report</a>.</p></li>
</ul>
</section>
<section id="cifar-c">
<h3>CIFAR-C<a class="headerlink" href="#cifar-c" title="Permalink to this heading">¶</a></h3>
<p><strong>Benchmarking neural network robustness to common corruptions and perturbations</strong></p>
<ul class="simple">
<li><p>Authors: <em>Dan Hendrycks and Thomas Dietterich</em></p></li>
<li><p>Paper: <a class="reference external" href="https://arxiv.org/pdf/1903.12261.pdf">ICLR 2019</a>.</p></li>
</ul>
</section>
<section id="cifar-10-h">
<h3>CIFAR-10 H<a class="headerlink" href="#cifar-10-h" title="Permalink to this heading">¶</a></h3>
<p><strong>Human uncertainty makes classification more robust</strong></p>
<ul class="simple">
<li><p>Authors: <em>Joshua C. Peterson, Ruairidh M. Battleday, Thomas L. Griffiths, and Olga Russakovsky</em></p></li>
<li><p>Paper: <a class="reference external" href="https://arxiv.org/pdf/1908.07086.pdf">ICCV 2019</a>.</p></li>
</ul>
</section>
<section id="svhn">
<h3>SVHN<a class="headerlink" href="#svhn" title="Permalink to this heading">¶</a></h3>
<p><strong>Reading digits in natural images with unsupervised feature learning</strong></p>
<ul class="simple">
<li><p>Authors: <em>Yuval Netzer, Tao Wang, Adam Coates, Alessandro Bissacco, Bo Wu, and Andrew Y. Ng</em></p></li>
<li><p>Paper: <a class="reference external" href="http://ufldl.stanford.edu/housenumbers/nips2011_housenumbers.pdf">NeurIPS Workshops 2011</a>.</p></li>
</ul>
</section>
<section id="imagenet">
<h3>ImageNet<a class="headerlink" href="#imagenet" title="Permalink to this heading">¶</a></h3>
<p><strong>Imagenet: A large-scale hierarchical image database</strong></p>
<ul class="simple">
<li><p>Authors: <em>Jia Deng, Wei Dong, Richard Socher, Li-Jia Li, Kai Li, and Li Fei-Fei</em></p></li>
<li><p>Paper: <a class="reference external" href="https://www.image-net.org/static_files/papers/imagenet_cvpr09.pdf">CVPR 2009</a>.</p></li>
</ul>
</section>
<section id="imagenet-a">
<h3>ImageNet-A<a class="headerlink" href="#imagenet-a" title="Permalink to this heading">¶</a></h3>
<p><strong>Natural adversarial examples</strong></p>
<ul class="simple">
<li><p>Authors: <em>Dan Hendrycks, Kevin Zhao, Steven Basart, Jacob Steinhardt, and Dawn Song</em></p></li>
<li><p>Paper: <a class="reference external" href="https://arxiv.org/pdf/1907.07174.pdf">CVPR 2021</a>.</p></li>
</ul>
</section>
<section id="imagenet-o">
<h3>ImageNet-O<a class="headerlink" href="#imagenet-o" title="Permalink to this heading">¶</a></h3>
<p><strong>Natural adversarial examples</strong></p>
<ul class="simple">
<li><p>Authors: <em>Dan Hendrycks, Kevin Zhao, Steven Basart, Jacob Steinhardt, and Dawn Song</em></p></li>
<li><p>Paper: <a class="reference external" href="https://arxiv.org/pdf/1907.07174.pdf">CVPR 2021</a>.</p></li>
</ul>
</section>
<section id="imagenet-r">
<h3>ImageNet-R<a class="headerlink" href="#imagenet-r" title="Permalink to this heading">¶</a></h3>
<p><strong>The many faces of robustness: A critical analysis of out-of-distribution generalization</strong></p>
<ul class="simple">
<li><p>Authors: <em>Dan Hendrycks, Steven Basart, Norman Mu, Saurav Kadavath, Frank Wang, Evan Dorundo, Rahul Desai, Tyler Zhu, Samyak Parajuli, Mike Guo, et al.</em></p></li>
<li><p>Paper: <a class="reference external" href="https://arxiv.org/pdf/2006.16241.pdf">ICCV 2021</a>.</p></li>
</ul>
</section>
<section id="textures">
<h3>Textures<a class="headerlink" href="#textures" title="Permalink to this heading">¶</a></h3>
<p><strong>ViM: Out-of-distribution with virtual-logit matching</strong></p>
<ul class="simple">
<li><p>Authors: <em>Haoqi Wang, Zhizhong Li, Litong Feng, and Wayne Zhang*</em></p></li>
<li><p>Paper: <a class="reference external" href="https://arxiv.org/pdf/2203.10807.pdf">CVPR 2022</a>.</p></li>
</ul>
</section>
</section>
<section id="classic-models">
<h2>Classic Models<a class="headerlink" href="#classic-models" title="Permalink to this heading">¶</a></h2>
<section id="resnet">
<h3>ResNet<a class="headerlink" href="#resnet" title="Permalink to this heading">¶</a></h3>
<p><strong>Deep Residual Learning for Image Recognition</strong></p>
<ul class="simple">
<li><p>Authors: <em>Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun</em></p></li>
<li><p>Paper: <a class="reference external" href="https://arxiv.org/pdf/1512.03385.pdf">CVPR 2016</a>.</p></li>
</ul>
</section>
<section id="wide-resnet">
<h3>Wide-ResNet<a class="headerlink" href="#wide-resnet" title="Permalink to this heading">¶</a></h3>
<p><strong>Wide Residual Networks</strong></p>
<ul class="simple">
<li><p>Authors: <em>Sergey Zagoruyko and Nikos Komodakis</em></p></li>
<li><p>Paper: <a class="reference external" href="https://arxiv.org/pdf/1605.07146.pdf">BMVC 2016</a>.</p></li>
</ul>
</section>
</section>
</section>


              </article>
              
            </div>
            <footer>
  
  <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
    
    
    <a href="contributing.html" class="btn btn-neutral" title="Contributing" accesskey="p"
      rel="prev"><img src="_static/images/chevron-right-teal.svg" class="previous-page"> Previous</a>
    
  </div>
  

  <hr>

  <div role="contentinfo">
    <p>
      &copy; Copyright 2023, Adrien Lafage and Olivier Laurent.

    </p>
  </div>
  
  <div>
    Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a
      href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the
      Docs</a>.
  </div>
   

</footer>
          </div>
        </div>

        <div class="pytorch-content-right" id="pytorch-content-right">
          <div class="pytorch-right-menu" id="pytorch-right-menu">
            <div class="pytorch-side-scroll" id="pytorch-side-scroll-right">
              <ul>
<li><a class="reference internal" href="#">References</a><ul>
<li><a class="reference internal" href="#uncertainty-models">Uncertainty Models</a><ul>
<li><a class="reference internal" href="#deep-ensembles">Deep Ensembles</a></li>
<li><a class="reference internal" href="#batchensemble">BatchEnsemble</a></li>
<li><a class="reference internal" href="#masksembles">Masksembles</a></li>
<li><a class="reference internal" href="#mimo">MIMO</a></li>
<li><a class="reference internal" href="#packed-ensembles">Packed-Ensembles</a></li>
</ul>
</li>
<li><a class="reference internal" href="#metrics">Metrics</a><ul>
<li><a class="reference internal" href="#expected-calibration-error">Expected Calibration Error</a></li>
</ul>
</li>
<li><a class="reference internal" href="#datasets">Datasets</a><ul>
<li><a class="reference internal" href="#cifar-10-cifar-100">CIFAR-10 &amp; CIFAR-100</a></li>
<li><a class="reference internal" href="#cifar-c">CIFAR-C</a></li>
<li><a class="reference internal" href="#cifar-10-h">CIFAR-10 H</a></li>
<li><a class="reference internal" href="#svhn">SVHN</a></li>
<li><a class="reference internal" href="#imagenet">ImageNet</a></li>
<li><a class="reference internal" href="#imagenet-a">ImageNet-A</a></li>
<li><a class="reference internal" href="#imagenet-o">ImageNet-O</a></li>
<li><a class="reference internal" href="#imagenet-r">ImageNet-R</a></li>
<li><a class="reference internal" href="#textures">Textures</a></li>
</ul>
</li>
<li><a class="reference internal" href="#classic-models">Classic Models</a><ul>
<li><a class="reference internal" href="#resnet">ResNet</a></li>
<li><a class="reference internal" href="#wide-resnet">Wide-ResNet</a></li>
</ul>
</li>
</ul>
</li>
</ul>

            </div>
          </div>
        </div>
    </section>
  </div>

  


  

  
  <script type="text/javascript" id="documentation_options" data-url_root="./"
    src="_static/documentation_options.js"></script>
  <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
  <script src="_static/jquery.js"></script>
  <script src="_static/underscore.js"></script>
  <script src="_static/_sphinx_javascript_frameworks_compat.js"></script>
  <script src="_static/doctools.js"></script>
  <script src="_static/sphinx_highlight.js"></script>
  <script src="_static/clipboard.min.js"></script>
  <script src="_static/copybutton.js"></script>
  

  

  <script type="text/javascript" src="_static/js/vendor/popper.min.js"></script>
  <script type="text/javascript" src="_static/js/vendor/bootstrap.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/list.js/1.5.0/list.min.js"></script>
  <script type="text/javascript" src="_static/js/theme.js"></script>

  <script type="text/javascript">
    jQuery(function () {
      SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

  <!-- Begin Footer -->

  <div class="container-fluid docs-tutorials-resources" id="docs-tutorials-resources">
  </div>

  <!-- End Footer -->

  <!-- Begin Mobile Menu -->

  <div class="mobile-main-menu">
    <div class="container-fluid">
      <div class="container">
        <div class="mobile-main-menu-header-container">
          <a class="header-logo" href="https://torch-uncertainty.github.io/" aria-label="OpenMMLab"></a>
          <a class="main-menu-close-button" href="#" data-behavior="close-mobile-menu"></a>
        </div>
      </div>
    </div>

    <div class="mobile-main-menu-links-container">
      <div class="main-menu">
        <ul>
          <li>
            <a href="https://github.com/ENSTA-U2IS/torch-uncertainty" target="_blank">GitHub</a>
          </li>
      </div>
    </div>
  </div>

  <!-- End Mobile Menu -->

  <script type="text/javascript" src="_static/js/vendor/anchor.min.js"></script>

  <script type="text/javascript">
    $(document).ready(function () {
      mobileMenu.bind();
      mobileTOC.bind();
      pytorchAnchors.bind();
      sideMenus.bind();
      scrollToAnchor.bind();
      highlightNavigation.bind();
      mainMenuDropdown.bind();
      filterTags.bind();

      // Add class to links that have code blocks, since we cannot create links in code blocks
      $("article.pytorch-article a span.pre").each(function (e) {
        $(this).closest("a").addClass("has-code");
      });
    })
  </script>
</body>

</html>