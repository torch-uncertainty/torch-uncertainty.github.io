


<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!-->
<html class="no-js" lang="en">
<!--<![endif]-->

<head>
  <meta charset="utf-8">
  <meta name="generator" content="Docutils 0.19: https://docutils.sourceforge.io/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>Improve Top-label Calibration with Temperature Scaling &mdash; TorchUncertainty 0.1.4 documentation</title>
  

  <link rel="shortcut icon" href="../_static/images/logo_torch_uncertainty.png" />
  
  

  

  
  
  

  

  <link rel="stylesheet" href="../_static/css/custom.css" type="text/css" />
  <!-- <link rel="stylesheet" href="../_static/pygments.css" type="text/css" /> -->
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../_static/css/custom.css" type="text/css" />
  <link rel="stylesheet" href="../_static/copybutton.css" type="text/css" />
  <link rel="stylesheet" href="../_static/sg_gallery.css" type="text/css" />
  <link rel="stylesheet" href="../_static/sg_gallery-binder.css" type="text/css" />
  <link rel="stylesheet" href="../_static/sg_gallery-dataframe.css" type="text/css" />
  <link rel="stylesheet" href="../_static/sg_gallery-rendered-html.css" type="text/css" />
  <link rel="index" title="Index" href="../genindex.html" />
  <link rel="search" title="Search" href="../search.html" />
  <link rel="next" title="Train a Bayesian Neural Network in Three Minutes" href="tutorial_bayesian.html" />
  <link rel="prev" title="Tutorials" href="index.html" />
  <!-- Google Analytics -->
  <script type="text/javascript">
    var collapsedSections = [];
  </script>
  
  <!-- End Google Analytics -->
  

  
  <script src="../_static/js/modernizr.min.js"></script>
  <script>
    MathJax = {
        chtml: {
            scale: 1,
            minScale: 1,
        },
        svg: {
            scale: 1,
            minScale: 1,
        }
    }
</script>

  <!-- Preload the theme fonts -->

<link rel="preload" href="../_static/fonts/FreightSans/freight-sans-book.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../_static/fonts/FreightSans/freight-sans-medium.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../_static/fonts/IBMPlexMono/IBMPlexMono-Medium.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../_static/fonts/FreightSans/freight-sans-bold.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../_static/fonts/FreightSans/freight-sans-medium-italic.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../_static/fonts/IBMPlexMono/IBMPlexMono-SemiBold.woff2" as="font" type="font/woff2" crossorigin="anonymous">

<!-- Preload the katex fonts -->

<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Math-Italic.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Main-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Main-Bold.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size1-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size4-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size2-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size3-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Caligraphic-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
  <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.15.2/css/all.css"
    integrity="sha384-vSIIfh2YWi9wW0r9iZe7RJPrKwp6bG+s9QZMoITbCckVJqGCCRhc+ccxNcdpHuYu" crossorigin="anonymous">
</head>

<div class="container-fluid header-holder tutorials-header" id="header-holder">
  <div class="container">
    <div class="header-container">
      <a class="header-logo" href="https://torch-uncertainty.github.io/"
        aria-label="OpenMMLab"></a>

      <div class="main-menu">
        <ul>
          <li>
            <a href="https://github.com/ENSTA-U2IS/torch-uncertainty" target="_blank">GitHub</a>
          </li>
        </ul>
      </div>

      <a class="main-menu-open-button" href="#" data-behavior="open-mobile-menu"></a>
    </div>
  </div>
</div>

<body class="pytorch-body">

   

  

  <div class="table-of-contents-link-wrapper">
    <span>Table of Contents</span>
    <a href="#" class="toggle-table-of-contents" data-behavior="toggle-table-of-contents"></a>
  </div>

  <nav data-toggle="wy-nav-shift" class="pytorch-left-menu" id="pytorch-left-menu">
    <div class="pytorch-side-scroll">
      <div class="pytorch-menu pytorch-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
        <div class="pytorch-left-menu-search">
          

          
          
          
          

          



<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search Docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        
        
        
        
        
        <p class="caption" role="heading"><span class="caption-text">Contents:</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../installation.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../quickstart.html">Quickstart</a></li>
<li class="toctree-l1"><a class="reference internal" href="../introduction_uncertainty.html">Introduction to Classification Uncertainty</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="index.html">Tutorials</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api.html">API reference</a></li>
<li class="toctree-l1"><a class="reference internal" href="../contributing.html">Contributing</a></li>
<li class="toctree-l1"><a class="reference internal" href="../references.html">References</a></li>
</ul>

        
        
      </div>
    </div>
  </nav>

  <div class="pytorch-container">
    <div class="pytorch-page-level-bar" id="pytorch-page-level-bar">
      <div class="pytorch-breadcrumbs-wrapper">
        















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="pytorch-breadcrumbs">
    
    <li>
      <a href="../index.html">
        Docs
      </a> &gt;
    </li>

    
    <li><a href="index.html">Tutorials</a> &gt;</li>
    
    <li>Improve Top-label Calibration with Temperature Scaling</li>
    
    <!-- 
    <li class="pytorch-breadcrumbs-aside">
      
      
      
      
      
      <a href="/zh_CN//auto_tutorials/tutorial_scaler.html" class="fa fa-language"> 以中文阅读</a>
      
      
    </li>
    
     -->
  </ul>

  
</div>
      </div>

      <div class="pytorch-shortcuts-wrapper" id="pytorch-shortcuts-wrapper">
        Shortcuts
      </div>
    </div>

    <section data-toggle="wy-nav-shift" id="pytorch-content-wrap" class="pytorch-content-wrap">
      <div class="pytorch-content-left">

        

        <div class="pytorch-call-to-action-links">
          <div id="tutorial-type">auto_tutorials/tutorial_scaler</div>

          <!-- <div id="google-colab-link">
            <img class="call-to-action-img" src="../_static/images/pytorch-colab.svg" />
            <div class="call-to-action-desktop-view">Run in Google Colab</div>
            <div class="call-to-action-mobile-view">Colab</div>
          </div> -->
          <div id="download-notebook-link">
            <img class="call-to-action-notebook-img" src="../_static/images/pytorch-download.svg" />
            <div class="call-to-action-desktop-view">Download Notebook</div>
            <div class="call-to-action-mobile-view">Notebook</div>
          </div>
          <div id="github-view-link">
            <img class="call-to-action-img" src="../_static/images/pytorch-github.svg" />
            <div class="call-to-action-desktop-view">View on GitHub</div>
            <div class="call-to-action-mobile-view">GitHub</div>
          </div>
        </div>

        
        
          <div class="rst-content">
            
            <div role="main" class="main-content" itemscope="itemscope" itemtype="http://schema.org/Article">
              <article itemprop="articleBody" id="pytorch-article" class="pytorch-article">
                
                
  <div class="sphx-glr-download-link-note admonition note">
<p class="admonition-title">Note</p>
<p><a class="reference internal" href="#sphx-glr-download-auto-tutorials-tutorial-scaler-py"><span class="std std-ref">Go to the end</span></a>
to download the full example code</p>
</div>
<section class="sphx-glr-example-title" id="improve-top-label-calibration-with-temperature-scaling">
<span id="sphx-glr-auto-tutorials-tutorial-scaler-py"></span><h1>Improve Top-label Calibration with Temperature Scaling<a class="headerlink" href="#improve-top-label-calibration-with-temperature-scaling" title="Permalink to this heading">¶</a></h1>
<p>In this tutorial, we use torch-uncertainty to improve the calibration of the top-label predictions
to improve the reliability of the underlying neural network.</p>
<p>We also see how to use the datamodules outside any Lightning Trainer.</p>
<section id="loading-the-utilities">
<h2>1. Loading the utilities<a class="headerlink" href="#loading-the-utilities" title="Permalink to this heading">¶</a></h2>
<p>In this tutorial, we will need:</p>
<ul class="simple">
<li><p>torch to download the pretrained model</p></li>
<li><p>the Calibration Error metric to compute the ECE and evaluate the top-label calibration</p></li>
<li><p>the CIFAR-100 datamodule to handle the data</p></li>
<li><p>the Temperature Scaler to improve the top-label calibration</p></li>
</ul>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">from</span> <span class="nn">torchmetrics</span> <span class="kn">import</span> <span class="n">CalibrationError</span>

<span class="kn">from</span> <span class="nn">torch_uncertainty.datamodules</span> <span class="kn">import</span> <span class="n">CIFAR100DataModule</span>
<span class="kn">from</span> <span class="nn">torch_uncertainty.post_processing</span> <span class="kn">import</span> <span class="n">TemperatureScaler</span>
</pre></div>
</div>
</section>
<section id="downloading-a-pre-trained-model">
<h2>2. Downloading a Pre-trained Model<a class="headerlink" href="#downloading-a-pre-trained-model" title="Permalink to this heading">¶</a></h2>
<p>To avoid training a model on CIFAR-100 from scratch, we will use here a model from <a class="reference external" href="https://github.com/chenyaofo/pytorch-cifar-models">https://github.com/chenyaofo/pytorch-cifar-models</a> (thank you!)
This can be done in a one liner:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">hub</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">&quot;chenyaofo/pytorch-cifar-models&quot;</span><span class="p">,</span> <span class="s2">&quot;cifar100_resnet20&quot;</span><span class="p">,</span> <span class="n">pretrained</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>/home/runner/work/torch-uncertainty/torch-uncertainty/.venv/lib/python3.10/site-packages/torch/hub.py:286: UserWarning: You are about to download and run code from an untrusted repository. In a future release, this won&#39;t be allowed. To add the repository to your trusted list, change the command to {calling_fn}(..., trust_repo=False) and a command prompt will appear asking for an explicit confirmation of trust, or load(..., trust_repo=True), which will assume that the prompt is to be answered with &#39;yes&#39;. You can also use load(..., trust_repo=&#39;check&#39;) which will only prompt for confirmation if the repo is not already trusted. This will eventually be the default behaviour
  warnings.warn(
Downloading: &quot;https://github.com/chenyaofo/pytorch-cifar-models/zipball/master&quot; to /home/runner/.cache/torch/hub/master.zip
Downloading: &quot;https://github.com/chenyaofo/pytorch-cifar-models/releases/download/resnet/cifar100_resnet20-23dac2f1.pt&quot; to /home/runner/.cache/torch/hub/checkpoints/cifar100_resnet20-23dac2f1.pt

  0%|          | 0.00/1.11M [00:00&lt;?, ?B/s]
100%|██████████| 1.11M/1.11M [00:00&lt;00:00, 17.6MB/s]
</pre></div>
</div>
</section>
<section id="setting-up-the-datamodule-and-dataloader">
<h2>3. Setting up the Datamodule and Dataloader<a class="headerlink" href="#setting-up-the-datamodule-and-dataloader" title="Permalink to this heading">¶</a></h2>
<p>To get the dataloader from the datamodule, just call prepare_data, setup, and
extract the first element of the test dataloader list. There are more than one
element if <cite>:attr:ood_detection</cite> is True.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">dm</span> <span class="o">=</span> <span class="n">CIFAR100DataModule</span><span class="p">(</span><span class="n">root</span><span class="o">=</span><span class="s2">&quot;./data&quot;</span><span class="p">,</span> <span class="n">ood_detection</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">32</span><span class="p">)</span>
<span class="n">dm</span><span class="o">.</span><span class="n">prepare_data</span><span class="p">()</span>
<span class="n">dm</span><span class="o">.</span><span class="n">setup</span><span class="p">(</span><span class="s2">&quot;test&quot;</span><span class="p">)</span>

<span class="c1"># Get the full test dataloader (unused in this tutorial)</span>
<span class="n">dataloader</span> <span class="o">=</span> <span class="n">dm</span><span class="o">.</span><span class="n">test_dataloader</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>Downloading https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz to data/cifar-100-python.tar.gz

  0%|          | 0/169001437 [00:00&lt;?, ?it/s]
  0%|          | 229376/169001437 [00:00&lt;01:13, 2293177.18it/s]
  2%|▏         | 3014656/169001437 [00:00&lt;00:09, 17296367.14it/s]
  5%|▍         | 8355840/169001437 [00:00&lt;00:04, 33642049.87it/s]
  8%|▊         | 13697024/169001437 [00:00&lt;00:03, 41396767.65it/s]
 11%|█▏        | 19070976/169001437 [00:00&lt;00:03, 45820802.92it/s]
 14%|█▍        | 24379392/169001437 [00:00&lt;00:03, 48163422.76it/s]
 18%|█▊        | 29949952/169001437 [00:00&lt;00:02, 50482039.38it/s]
 21%|██        | 35389440/169001437 [00:00&lt;00:02, 51630006.20it/s]
 24%|██▍       | 40796160/169001437 [00:00&lt;00:02, 52350252.40it/s]
 27%|██▋       | 46202880/169001437 [00:01&lt;00:02, 52859469.98it/s]
 31%|███       | 51609600/169001437 [00:01&lt;00:02, 53104005.74it/s]
 34%|███▍      | 57049088/169001437 [00:01&lt;00:02, 53460006.74it/s]
 37%|███▋      | 62488576/169001437 [00:01&lt;00:01, 53572162.97it/s]
 40%|████      | 67960832/169001437 [00:01&lt;00:01, 53808462.45it/s]
 43%|████▎     | 73400320/169001437 [00:01&lt;00:01, 53908908.64it/s]
 47%|████▋     | 78905344/169001437 [00:01&lt;00:01, 54131531.97it/s]
 50%|████▉     | 84344832/169001437 [00:01&lt;00:01, 54100101.54it/s]
 53%|█████▎    | 89849856/169001437 [00:01&lt;00:01, 54237853.38it/s]
 56%|█████▋    | 95289344/169001437 [00:01&lt;00:01, 54219431.51it/s]
 60%|█████▉    | 100761600/169001437 [00:02&lt;00:01, 54348583.11it/s]
 63%|██████▎   | 106201088/169001437 [00:02&lt;00:01, 54279325.56it/s]
 66%|██████▌   | 111640576/169001437 [00:02&lt;00:01, 54313825.67it/s]
 69%|██████▉   | 117112832/169001437 [00:02&lt;00:00, 54333125.33it/s]
 73%|███████▎  | 122552320/169001437 [00:02&lt;00:00, 54217003.69it/s]
 76%|███████▌  | 128057344/169001437 [00:02&lt;00:00, 54222443.64it/s]
 79%|███████▉  | 133562368/169001437 [00:02&lt;00:00, 54306051.25it/s]
 82%|████████▏ | 139001856/169001437 [00:02&lt;00:00, 54303213.93it/s]
 85%|████████▌ | 144474112/169001437 [00:02&lt;00:00, 54238891.30it/s]
 89%|████████▊ | 149913600/169001437 [00:02&lt;00:00, 54106200.78it/s]
 93%|█████████▎| 156336128/169001437 [00:03&lt;00:00, 57056210.02it/s]
 99%|█████████▊| 166756352/169001437 [00:03&lt;00:00, 71085460.07it/s]
100%|██████████| 169001437/169001437 [00:03&lt;00:00, 53870529.50it/s]
Extracting data/cifar-100-python.tar.gz to data
Files already downloaded and verified
</pre></div>
</div>
</section>
<section id="iterate-on-the-dataloader-and-compute-the-ece">
<h2>4. Iterate on the Dataloader and compute the ECE<a class="headerlink" href="#iterate-on-the-dataloader-and-compute-the-ece" title="Permalink to this heading">¶</a></h2>
<p>We first split the original test set into a calibration set and a test set for proper evaluation.</p>
<p>When computing the ECE, you need to provide the likelihoods associated with the inputs.
To do this, just call PyTorch’s softmax.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">DataLoader</span><span class="p">,</span> <span class="n">random_split</span>

<span class="c1"># Split datasets</span>
<span class="n">dataset</span> <span class="o">=</span> <span class="n">dm</span><span class="o">.</span><span class="n">test</span>
<span class="n">cal_dataset</span><span class="p">,</span> <span class="n">test_dataset</span> <span class="o">=</span> <span class="n">random_split</span><span class="p">(</span><span class="n">dataset</span><span class="p">,</span> <span class="p">[</span><span class="mi">1000</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span><span class="o">-</span><span class="mi">1000</span><span class="p">])</span>
<span class="n">cal_dataloader</span><span class="p">,</span> <span class="n">test_dataloader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">cal_dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">32</span><span class="p">),</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">test_dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">32</span><span class="p">)</span>

<span class="c1"># Initialize the ECE</span>
<span class="n">ece</span> <span class="o">=</span> <span class="n">CalibrationError</span><span class="p">(</span><span class="n">task</span><span class="o">=</span><span class="s2">&quot;multiclass&quot;</span><span class="p">,</span> <span class="n">num_classes</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>

<span class="c1"># Iterate on the calibration dataloader</span>
<span class="k">for</span> <span class="n">sample</span><span class="p">,</span> <span class="n">target</span> <span class="ow">in</span> <span class="n">test_dataloader</span><span class="p">:</span>
    <span class="n">logits</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">sample</span><span class="p">)</span>
    <span class="n">ece</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="n">target</span><span class="p">)</span>

<span class="c1"># Compute &amp; print the calibration error</span>
<span class="n">cal</span> <span class="o">=</span> <span class="n">ece</span><span class="o">.</span><span class="n">compute</span><span class="p">()</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;ECE before scaling - </span><span class="si">{</span><span class="n">cal</span><span class="o">*</span><span class="mi">100</span><span class="si">:</span><span class="s2">.3</span><span class="si">}</span><span class="s2">%.&quot;</span><span class="p">)</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>ECE before scaling - 10.8%.
</pre></div>
</div>
</section>
<section id="fit-the-scaler-to-improve-the-calibration">
<h2>5. Fit the Scaler to Improve the Calibration<a class="headerlink" href="#fit-the-scaler-to-improve-the-calibration" title="Permalink to this heading">¶</a></h2>
<p>The TemperatureScaler has one parameter that can be used to temper the softmax.
We minimize the tempered cross-entropy on a calibration set that we define here as
a subset of the test set and containing 1000 data.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># Fit the scaler on the calibration dataset</span>
<span class="n">scaler</span> <span class="o">=</span> <span class="n">TemperatureScaler</span><span class="p">()</span>
<span class="n">scaler</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">,</span> <span class="n">calib_loader</span><span class="o">=</span><span class="n">cal_dataloader</span><span class="p">)</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>  0%|          | 0/32 [00:00&lt;?, ?it/s]
  9%|▉         | 3/32 [00:00&lt;00:01, 27.31it/s]
 19%|█▉        | 6/32 [00:00&lt;00:00, 26.62it/s]
 28%|██▊       | 9/32 [00:00&lt;00:00, 26.87it/s]
 38%|███▊      | 12/32 [00:00&lt;00:00, 26.64it/s]
 47%|████▋     | 15/32 [00:00&lt;00:00, 26.21it/s]
 56%|█████▋    | 18/32 [00:00&lt;00:00, 26.63it/s]
 66%|██████▌   | 21/32 [00:00&lt;00:00, 27.03it/s]
 75%|███████▌  | 24/32 [00:00&lt;00:00, 27.25it/s]
 84%|████████▍ | 27/32 [00:01&lt;00:00, 27.27it/s]
 94%|█████████▍| 30/32 [00:01&lt;00:00, 27.24it/s]
100%|██████████| 32/32 [00:01&lt;00:00, 27.36it/s]
</pre></div>
</div>
</section>
<section id="iterate-again-to-compute-the-improved-ece">
<h2>6. Iterate again to compute the improved ECE<a class="headerlink" href="#iterate-again-to-compute-the-improved-ece" title="Permalink to this heading">¶</a></h2>
<p>We create a wrapper of the original model and the scaler using torch.nn.Sequential.
This is possible because the scaler is derived from nn.Module.</p>
<p>Note that you will need to first reset the ECE metric to avoid mixing the scores of the previous and current iterations.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># Create the calibrated model</span>
<span class="n">cal_model</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">scaler</span><span class="p">)</span>

<span class="c1"># Reset the ECE</span>
<span class="n">ece</span><span class="o">.</span><span class="n">reset</span><span class="p">()</span>

<span class="c1"># Iterate on the test dataloader</span>
<span class="k">for</span> <span class="n">sample</span><span class="p">,</span> <span class="n">target</span> <span class="ow">in</span> <span class="n">test_dataloader</span><span class="p">:</span>
    <span class="n">logits</span> <span class="o">=</span> <span class="n">cal_model</span><span class="p">(</span><span class="n">sample</span><span class="p">)</span>
    <span class="n">ece</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">logits</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">),</span> <span class="n">target</span><span class="p">)</span>

<span class="n">cal</span> <span class="o">=</span> <span class="n">ece</span><span class="o">.</span><span class="n">compute</span><span class="p">()</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;ECE after scaling - </span><span class="si">{</span><span class="n">cal</span><span class="o">*</span><span class="mi">100</span><span class="si">:</span><span class="s2">.3</span><span class="si">}</span><span class="s2">%.&quot;</span><span class="p">)</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>ECE after scaling - 1.4%.
</pre></div>
</div>
<p>The top-label calibration should be improved.</p>
<section id="notes">
<h3>Notes<a class="headerlink" href="#notes" title="Permalink to this heading">¶</a></h3>
<p>Temperature scaling is very efficient when the calibration set is representative of the test set.
In this case, we say that the calibration and test set are drawn from the same distribution.
However, this may not be True in real-world cases where dataset shift could happen.</p>
</section>
<section id="references">
<h3>References<a class="headerlink" href="#references" title="Permalink to this heading">¶</a></h3>
<ul class="simple">
<li><p><strong>Expected Calibration Error:</strong> Naeini, M. P., Cooper, G. F., &amp; Hauskrecht, M. (2015). Obtaining Well Calibrated Probabilities Using Bayesian Binning. In <a class="reference external" href="https://arxiv.org/pdf/1411.0160.pdf">AAAI 2015</a></p></li>
<li><p><strong>Temperature Scaling:</strong> Guo, C., Pleiss, G., Sun, Y., &amp; Weinberger, K. Q. (2017). On calibration of modern neural networks. In <a class="reference external" href="https://arxiv.org/pdf/1706.04599.pdf">ICML 2017</a></p></li>
</ul>
<p class="sphx-glr-timing"><strong>Total running time of the script:</strong> (0 minutes 33.398 seconds)</p>
<div class="sphx-glr-footer sphx-glr-footer-example docutils container" id="sphx-glr-download-auto-tutorials-tutorial-scaler-py">
<div class="sphx-glr-download sphx-glr-download-python docutils container">
<p><a class="reference download internal" download="" href="../_downloads/1be01891b8f2e6a7bd1a0bb5e68c5f96/tutorial_scaler.py"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Python</span> <span class="pre">source</span> <span class="pre">code:</span> <span class="pre">tutorial_scaler.py</span></code></a></p>
</div>
<div class="sphx-glr-download sphx-glr-download-jupyter docutils container">
<p><a class="reference download internal" download="" href="../_downloads/35097fc86b1c61efee915836b2ab44fc/tutorial_scaler.ipynb"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Jupyter</span> <span class="pre">notebook:</span> <span class="pre">tutorial_scaler.ipynb</span></code></a></p>
</div>
</div>
<p class="sphx-glr-signature"><a class="reference external" href="https://sphinx-gallery.github.io">Gallery generated by Sphinx-Gallery</a></p>
</section>
</section>
</section>


              </article>
              
            </div>
            <footer>
  
  <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
    
    <a href="tutorial_bayesian.html" class="btn btn-neutral float-right" title="Train a Bayesian Neural Network in Three Minutes" accesskey="n"
      rel="next">Next <img src="../_static/images/chevron-right-teal.svg"
        class="next-page"></a>
    
    
    <a href="index.html" class="btn btn-neutral" title="Tutorials" accesskey="p"
      rel="prev"><img src="../_static/images/chevron-right-teal.svg" class="previous-page"> Previous</a>
    
  </div>
  

  <hr>

  <div role="contentinfo">
    <p>
      &copy; Copyright 2023, Adrien Lafage and Olivier Laurent.

    </p>
  </div>
  
  <div>
    Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a
      href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the
      Docs</a>.
  </div>
   

</footer>
          </div>
        </div>

        <div class="pytorch-content-right" id="pytorch-content-right">
          <div class="pytorch-right-menu" id="pytorch-right-menu">
            <div class="pytorch-side-scroll" id="pytorch-side-scroll-right">
              <ul>
<li><a class="reference internal" href="#">Improve Top-label Calibration with Temperature Scaling</a><ul>
<li><a class="reference internal" href="#loading-the-utilities">1. Loading the utilities</a></li>
<li><a class="reference internal" href="#downloading-a-pre-trained-model">2. Downloading a Pre-trained Model</a></li>
<li><a class="reference internal" href="#setting-up-the-datamodule-and-dataloader">3. Setting up the Datamodule and Dataloader</a></li>
<li><a class="reference internal" href="#iterate-on-the-dataloader-and-compute-the-ece">4. Iterate on the Dataloader and compute the ECE</a></li>
<li><a class="reference internal" href="#fit-the-scaler-to-improve-the-calibration">5. Fit the Scaler to Improve the Calibration</a></li>
<li><a class="reference internal" href="#iterate-again-to-compute-the-improved-ece">6. Iterate again to compute the improved ECE</a><ul>
<li><a class="reference internal" href="#notes">Notes</a></li>
<li><a class="reference internal" href="#references">References</a></li>
</ul>
</li>
</ul>
</li>
</ul>

            </div>
          </div>
        </div>
    </section>
  </div>

  


  

  
  <script type="text/javascript" id="documentation_options" data-url_root="../"
    src="../_static/documentation_options.js"></script>
  <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
  <script src="../_static/jquery.js"></script>
  <script src="../_static/underscore.js"></script>
  <script src="../_static/_sphinx_javascript_frameworks_compat.js"></script>
  <script src="../_static/doctools.js"></script>
  <script src="../_static/sphinx_highlight.js"></script>
  <script src="../_static/clipboard.min.js"></script>
  <script src="../_static/copybutton.js"></script>
  

  

  <script type="text/javascript" src="../_static/js/vendor/popper.min.js"></script>
  <script type="text/javascript" src="../_static/js/vendor/bootstrap.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/list.js/1.5.0/list.min.js"></script>
  <script type="text/javascript" src="../_static/js/theme.js"></script>

  <script type="text/javascript">
    jQuery(function () {
      SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

  <!-- Begin Footer -->

  <div class="container-fluid docs-tutorials-resources" id="docs-tutorials-resources">
  </div>

  <!-- End Footer -->

  <!-- Begin Mobile Menu -->

  <div class="mobile-main-menu">
    <div class="container-fluid">
      <div class="container">
        <div class="mobile-main-menu-header-container">
          <a class="header-logo" href="https://torch-uncertainty.github.io/" aria-label="OpenMMLab"></a>
          <a class="main-menu-close-button" href="#" data-behavior="close-mobile-menu"></a>
        </div>
      </div>
    </div>

    <div class="mobile-main-menu-links-container">
      <div class="main-menu">
        <ul>
          <li>
            <a href="https://github.com/ENSTA-U2IS/torch-uncertainty" target="_blank">GitHub</a>
          </li>
      </div>
    </div>
  </div>

  <!-- End Mobile Menu -->

  <script type="text/javascript" src="../_static/js/vendor/anchor.min.js"></script>

  <script type="text/javascript">
    $(document).ready(function () {
      mobileMenu.bind();
      mobileTOC.bind();
      pytorchAnchors.bind();
      sideMenus.bind();
      scrollToAnchor.bind();
      highlightNavigation.bind();
      mainMenuDropdown.bind();
      filterTags.bind();

      // Add class to links that have code blocks, since we cannot create links in code blocks
      $("article.pytorch-article a span.pre").each(function (e) {
        $(this).closest("a").addClass("has-code");
      });
    })
  </script>
</body>

</html>