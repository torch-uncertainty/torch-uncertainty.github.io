


<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!-->
<html class="no-js" lang="en">
<!--<![endif]-->

<head>
  <meta charset="utf-8">
  <meta name="generator" content="Docutils 0.19: https://docutils.sourceforge.io/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>Improve Top-label Calibration with Temperature Scaling &mdash; TorchUncertainty 0.3.0 documentation</title>
  

  <link rel="shortcut icon" href="../_static/images/logo_torch_uncertainty.png" />
  
  

  

  
  
  

  

  <link rel="stylesheet" href="../_static/css/custom.css" type="text/css" />
  <!-- <link rel="stylesheet" href="../_static/pygments.css" type="text/css" /> -->
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../_static/css/custom.css" type="text/css" />
  <link rel="stylesheet" href="../_static/copybutton.css" type="text/css" />
  <link rel="stylesheet" href="../_static/sphinx-codeautolink.css" type="text/css" />
  <link rel="stylesheet" href="../_static/sg_gallery.css" type="text/css" />
  <link rel="stylesheet" href="../_static/sg_gallery-binder.css" type="text/css" />
  <link rel="stylesheet" href="../_static/sg_gallery-dataframe.css" type="text/css" />
  <link rel="stylesheet" href="../_static/sg_gallery-rendered-html.css" type="text/css" />
  <link rel="index" title="Index" href="../genindex.html" />
  <link rel="search" title="Search" href="../search.html" />
  <link rel="next" title="Training a LeNet with Monte-Carlo Dropout" href="tutorial_mc_dropout.html" />
  <link rel="prev" title="Tutorials" href="index.html" />
  <!-- Google Analytics -->
  <script type="text/javascript">
    var collapsedSections = [];
  </script>
  
  <!-- End Google Analytics -->
  

  
  <script src="../_static/js/modernizr.min.js"></script>
  <script>
    MathJax = {
        chtml: {
            scale: 1,
            minScale: 1,
        },
        svg: {
            scale: 1,
            minScale: 1,
        }
    }
</script>

  <!-- Preload the theme fonts -->

<link rel="preload" href="../_static/fonts/FreightSans/freight-sans-book.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../_static/fonts/FreightSans/freight-sans-medium.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../_static/fonts/IBMPlexMono/IBMPlexMono-Medium.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../_static/fonts/FreightSans/freight-sans-bold.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../_static/fonts/FreightSans/freight-sans-medium-italic.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../_static/fonts/IBMPlexMono/IBMPlexMono-SemiBold.woff2" as="font" type="font/woff2" crossorigin="anonymous">

<!-- Preload the katex fonts -->

<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Math-Italic.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Main-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Main-Bold.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size1-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size4-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size2-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size3-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Caligraphic-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
  <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.15.2/css/all.css"
    integrity="sha384-vSIIfh2YWi9wW0r9iZe7RJPrKwp6bG+s9QZMoITbCckVJqGCCRhc+ccxNcdpHuYu" crossorigin="anonymous">
</head>

<div class="container-fluid header-holder tutorials-header" id="header-holder">
  <div class="container">
    <div class="header-container">
      <a class="header-logo" href="https://torch-uncertainty.github.io/"
        aria-label="OpenMMLab"></a>

      <div class="main-menu">
        <ul>
          <li>
            <a href="https://github.com/ENSTA-U2IS-AI/torch-uncertainty" target="_blank">GitHub</a>
          </li>
        </ul>
      </div>

      <a class="main-menu-open-button" href="#" data-behavior="open-mobile-menu"></a>
    </div>
  </div>
</div>

<body class="pytorch-body">

   

  

  <div class="table-of-contents-link-wrapper">
    <span>Table of Contents</span>
    <a href="#" class="toggle-table-of-contents" data-behavior="toggle-table-of-contents"></a>
  </div>

  <nav data-toggle="wy-nav-shift" class="pytorch-left-menu" id="pytorch-left-menu">
    <div class="pytorch-side-scroll">
      <div class="pytorch-menu pytorch-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
        <div class="pytorch-left-menu-search">
          

          
          
          
          

          



<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search Docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        
        
        
        
        
        <p class="caption" role="heading"><span class="caption-text">Contents:</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../installation.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../quickstart.html">Quickstart</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="index.html">Tutorials</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cli_guide.html">CLI Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api.html">API Reference</a></li>
<li class="toctree-l1"><a class="reference internal" href="../contributing.html">Contributing</a></li>
<li class="toctree-l1"><a class="reference internal" href="../references.html">References</a></li>
</ul>

        
        
      </div>
    </div>
  </nav>

  <div class="pytorch-container">
    <div class="pytorch-page-level-bar" id="pytorch-page-level-bar">
      <div class="pytorch-breadcrumbs-wrapper">
        















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="pytorch-breadcrumbs">
    
    <li>
      <a href="../index.html">
        Docs
      </a> &gt;
    </li>

    
    <li><a href="index.html">Tutorials</a> &gt;</li>
    
    <li>Improve Top-label Calibration with Temperature Scaling</li>
    
    <!-- 
    <li class="pytorch-breadcrumbs-aside">
      
      
      
      
      
      <a href="/zh_CN//auto_tutorials/tutorial_scaler.html" class="fa fa-language"> 以中文阅读</a>
      
      
    </li>
    
     -->
  </ul>

  
</div>
      </div>

      <div class="pytorch-shortcuts-wrapper" id="pytorch-shortcuts-wrapper">
        Shortcuts
      </div>
    </div>

    <section data-toggle="wy-nav-shift" id="pytorch-content-wrap" class="pytorch-content-wrap">
      <div class="pytorch-content-left">

        

        <div class="pytorch-call-to-action-links">
          <div id="tutorial-type">auto_tutorials/tutorial_scaler</div>

          <!-- <div id="google-colab-link">
            <img class="call-to-action-img" src="../_static/images/pytorch-colab.svg" />
            <div class="call-to-action-desktop-view">Run in Google Colab</div>
            <div class="call-to-action-mobile-view">Colab</div>
          </div> -->
          <div id="download-notebook-link">
            <img class="call-to-action-notebook-img" src="../_static/images/pytorch-download.svg" />
            <div class="call-to-action-desktop-view">Download Notebook</div>
            <div class="call-to-action-mobile-view">Notebook</div>
          </div>
          <div id="github-view-link">
            <img class="call-to-action-img" src="../_static/images/pytorch-github.svg" />
            <div class="call-to-action-desktop-view">View on GitHub</div>
            <div class="call-to-action-mobile-view">GitHub</div>
          </div>
        </div>

        
        
          <div class="rst-content">
            
            <div role="main" class="main-content" itemscope="itemscope" itemtype="http://schema.org/Article">
              <article itemprop="articleBody" id="pytorch-article" class="pytorch-article">
                
                
  <div class="sphx-glr-download-link-note admonition note">
<p class="admonition-title">Note</p>
<p><a class="reference internal" href="#sphx-glr-download-auto-tutorials-tutorial-scaler-py"><span class="std std-ref">Go to the end</span></a>
to download the full example code.</p>
</div>
<section class="sphx-glr-example-title" id="improve-top-label-calibration-with-temperature-scaling">
<span id="sphx-glr-auto-tutorials-tutorial-scaler-py"></span><h1>Improve Top-label Calibration with Temperature Scaling<a class="headerlink" href="#improve-top-label-calibration-with-temperature-scaling" title="Permalink to this heading">¶</a></h1>
<p>In this tutorial, we use <em>TorchUncertainty</em> to improve the calibration
of the top-label predictions and the reliability of the underlying neural network.</p>
<p>This tutorial provides extensive details on how to use the TemperatureScaler
class, however, this is done automatically in the classification routine when setting
the <cite>calibration_set</cite> to val or test.</p>
<p>Through this tutorial, we also see how to use the datamodules outside any Lightning trainers,
and how to use TorchUncertainty’s models.</p>
<section id="loading-the-utilities">
<h2>1. Loading the Utilities<a class="headerlink" href="#loading-the-utilities" title="Permalink to this heading">¶</a></h2>
<p>In this tutorial, we will need:</p>
<ul class="simple">
<li><p>TorchUncertainty’s Calibration Error metric to compute to evaluate the top-label calibration with ECE and plot the reliability diagrams</p></li>
<li><p>the CIFAR-100 datamodule to handle the data</p></li>
<li><p>a ResNet 18 as starting model</p></li>
<li><p>the temperature scaler to improve the top-label calibration</p></li>
<li><p>a utility function to download HF models easily</p></li>
</ul>
<p>If you use the classification routine, the plots will be automatically available in the tensorboard logs if you use the <cite>log_plots</cite> flag.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">torch_uncertainty.datamodules</span> <span class="kn">import</span> <span class="n">CIFAR100DataModule</span>
<span class="kn">from</span> <span class="nn">torch_uncertainty.metrics</span> <span class="kn">import</span> <span class="n">CalibrationError</span>
<span class="kn">from</span> <span class="nn">torch_uncertainty.models.resnet</span> <span class="kn">import</span> <span class="n">resnet</span>
<span class="kn">from</span> <span class="nn">torch_uncertainty.post_processing</span> <span class="kn">import</span> <span class="n">TemperatureScaler</span>
<span class="kn">from</span> <span class="nn">torch_uncertainty.utils</span> <span class="kn">import</span> <span class="n">load_hf</span>
</pre></div>
</div>
</section>
<section id="loading-a-model-from-torchuncertainty-s-hf">
<h2>2. Loading a model from TorchUncertainty’s HF<a class="headerlink" href="#loading-a-model-from-torchuncertainty-s-hf" title="Permalink to this heading">¶</a></h2>
<p>To avoid training a model on CIFAR-100 from scratch, we load a model from Hugging Face.
This can be done in a one liner:</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Build the model</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">resnet</span><span class="p">(</span><span class="n">in_channels</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">num_classes</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">arch</span><span class="o">=</span><span class="mi">18</span><span class="p">,</span> <span class="n">style</span><span class="o">=</span><span class="s2">&quot;cifar&quot;</span><span class="p">,</span> <span class="n">conv_bias</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

<span class="c1"># Download the weights (the config is not used here)</span>
<span class="n">weights</span><span class="p">,</span> <span class="n">config</span> <span class="o">=</span> <span class="n">load_hf</span><span class="p">(</span><span class="s2">&quot;resnet18_c100&quot;</span><span class="p">)</span>

<span class="c1"># Load the weights in the pre-built model</span>
<span class="n">model</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">weights</span><span class="p">)</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>/opt/hostedtoolcache/Python/3.10.15/x64/lib/python3.10/site-packages/torch_uncertainty/utils/hub.py:46: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don&#39;t have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  weight = torch.load(weight_path, map_location=torch.device(&quot;cpu&quot;))

&lt;All keys matched successfully&gt;
</pre></div>
</div>
</section>
<section id="setting-up-the-datamodule-and-dataloaders">
<h2>3. Setting up the Datamodule and Dataloaders<a class="headerlink" href="#setting-up-the-datamodule-and-dataloaders" title="Permalink to this heading">¶</a></h2>
<p>To get the dataloader from the datamodule, just call prepare_data, setup, and
extract the first element of the test dataloader list. There are more than one
element if eval_ood is True: the dataloader of in-distribution data and the dataloader
of out-of-distribution data. Otherwise, it is a list of 1 element.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="n">dm</span> <span class="o">=</span> <span class="n">CIFAR100DataModule</span><span class="p">(</span><span class="n">root</span><span class="o">=</span><span class="s2">&quot;./data&quot;</span><span class="p">,</span> <span class="n">eval_ood</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">32</span><span class="p">)</span>
<span class="n">dm</span><span class="o">.</span><span class="n">prepare_data</span><span class="p">()</span>
<span class="n">dm</span><span class="o">.</span><span class="n">setup</span><span class="p">(</span><span class="s2">&quot;test&quot;</span><span class="p">)</span>

<span class="c1"># Get the full test dataloader (unused in this tutorial)</span>
<span class="n">dataloader</span> <span class="o">=</span> <span class="n">dm</span><span class="o">.</span><span class="n">test_dataloader</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>Downloading https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz to data/cifar-100-python.tar.gz

  0%|          | 0.00/169M [00:00&lt;?, ?B/s]
  1%|          | 852k/169M [00:00&lt;00:21, 7.76MB/s]
  6%|▋         | 10.6M/169M [00:00&lt;00:02, 57.5MB/s]
 13%|█▎        | 21.5M/169M [00:00&lt;00:01, 80.0MB/s]
 20%|█▉        | 33.0M/169M [00:00&lt;00:01, 93.3MB/s]
 26%|██▌       | 44.2M/169M [00:00&lt;00:01, 99.6MB/s]
 32%|███▏      | 54.6M/169M [00:00&lt;00:01, 101MB/s]
 39%|███▉      | 65.7M/169M [00:00&lt;00:00, 104MB/s]
 46%|████▌     | 76.9M/169M [00:00&lt;00:00, 107MB/s]
 52%|█████▏    | 87.7M/169M [00:00&lt;00:00, 106MB/s]
 59%|█████▊    | 99.2M/169M [00:01&lt;00:00, 109MB/s]
 65%|██████▌   | 110M/169M [00:01&lt;00:00, 109MB/s]
 72%|███████▏  | 121M/169M [00:01&lt;00:00, 110MB/s]
 78%|███████▊  | 132M/169M [00:01&lt;00:00, 109MB/s]
 85%|████████▌ | 144M/169M [00:01&lt;00:00, 111MB/s]
 92%|█████████▏| 155M/169M [00:01&lt;00:00, 112MB/s]
 99%|█████████▊| 167M/169M [00:01&lt;00:00, 113MB/s]
100%|██████████| 169M/169M [00:01&lt;00:00, 103MB/s]
Extracting data/cifar-100-python.tar.gz to data
Files already downloaded and verified
</pre></div>
</div>
</section>
<section id="iterating-on-the-dataloader-and-computing-the-ece">
<h2>4. Iterating on the Dataloader and Computing the ECE<a class="headerlink" href="#iterating-on-the-dataloader-and-computing-the-ece" title="Permalink to this heading">¶</a></h2>
<p>We first split the original test set into a calibration set and a test set for proper evaluation.</p>
<p>When computing the ECE, you need to provide the likelihoods associated with the inputs.
To do this, just call PyTorch’s softmax.</p>
<p>To avoid lengthy computations (without GPU), we restrict the calibration computation to a subset
of the test set.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">DataLoader</span><span class="p">,</span> <span class="n">random_split</span>

<span class="c1"># Split datasets</span>
<span class="n">dataset</span> <span class="o">=</span> <span class="n">dm</span><span class="o">.</span><span class="n">test</span>
<span class="n">cal_dataset</span><span class="p">,</span> <span class="n">test_dataset</span><span class="p">,</span> <span class="n">other</span> <span class="o">=</span> <span class="n">random_split</span><span class="p">(</span>
    <span class="n">dataset</span><span class="p">,</span> <span class="p">[</span><span class="mi">1000</span><span class="p">,</span> <span class="mi">1000</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span> <span class="o">-</span> <span class="mi">2000</span><span class="p">]</span>
<span class="p">)</span>
<span class="n">test_dataloader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">test_dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">32</span><span class="p">)</span>

<span class="c1"># Initialize the ECE</span>
<span class="n">ece</span> <span class="o">=</span> <span class="n">CalibrationError</span><span class="p">(</span><span class="n">task</span><span class="o">=</span><span class="s2">&quot;multiclass&quot;</span><span class="p">,</span> <span class="n">num_classes</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>

<span class="c1"># Iterate on the calibration dataloader</span>
<span class="k">for</span> <span class="n">sample</span><span class="p">,</span> <span class="n">target</span> <span class="ow">in</span> <span class="n">test_dataloader</span><span class="p">:</span>
    <span class="n">logits</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">sample</span><span class="p">)</span>
    <span class="n">probs</span> <span class="o">=</span> <span class="n">logits</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">ece</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">probs</span><span class="p">,</span> <span class="n">target</span><span class="p">)</span>

<span class="c1"># Compute &amp; print the calibration error</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;ECE before scaling - </span><span class="si">{</span><span class="n">ece</span><span class="o">.</span><span class="n">compute</span><span class="p">()</span><span class="si">:</span><span class="s2">.3%</span><span class="si">}</span><span class="s2">.&quot;</span><span class="p">)</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>ECE before scaling - 11.944%.
</pre></div>
</div>
<p>We also compute and plot the top-label calibration figure. We see that the
model is not well calibrated.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">ece</span><span class="o">.</span><span class="n">plot</span><span class="p">()</span>
<span class="n">fig</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
<img src="../_images/sphx_glr_tutorial_scaler_001.png" srcset="../_images/sphx_glr_tutorial_scaler_001.png" alt="Reliability Diagram" class = "sphx-glr-single-img"/></section>
<section id="fitting-the-scaler-to-improve-the-calibration">
<h2>5. Fitting the Scaler to Improve the Calibration<a class="headerlink" href="#fitting-the-scaler-to-improve-the-calibration" title="Permalink to this heading">¶</a></h2>
<p>The TemperatureScaler has one parameter that can be used to temper the softmax.
We minimize the tempered cross-entropy on a calibration set that we define here as
a subset of the test set and containing 1000 data. Look at the code run by TemperatureScaler
<cite>fit</cite> method for more details.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Fit the scaler on the calibration dataset</span>
<span class="n">scaled_model</span> <span class="o">=</span> <span class="n">TemperatureScaler</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">)</span>
<span class="n">scaled_model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">calibration_set</span><span class="o">=</span><span class="n">cal_dataset</span><span class="p">)</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>  0%|          | 0/32 [00:00&lt;?, ?it/s]
  3%|▎         | 1/32 [00:00&lt;00:07,  3.92it/s]
  6%|▋         | 2/32 [00:00&lt;00:07,  3.94it/s]
  9%|▉         | 3/32 [00:00&lt;00:07,  3.97it/s]
 12%|█▎        | 4/32 [00:01&lt;00:07,  3.93it/s]
 16%|█▌        | 5/32 [00:01&lt;00:06,  3.97it/s]
 19%|█▉        | 6/32 [00:01&lt;00:06,  3.99it/s]
 22%|██▏       | 7/32 [00:01&lt;00:06,  4.01it/s]
 25%|██▌       | 8/32 [00:02&lt;00:06,  3.99it/s]
 28%|██▊       | 9/32 [00:02&lt;00:05,  3.98it/s]
 31%|███▏      | 10/32 [00:02&lt;00:05,  3.98it/s]
 34%|███▍      | 11/32 [00:02&lt;00:05,  3.96it/s]
 38%|███▊      | 12/32 [00:03&lt;00:05,  3.96it/s]
 41%|████      | 13/32 [00:03&lt;00:04,  3.99it/s]
 44%|████▍     | 14/32 [00:03&lt;00:04,  3.92it/s]
 47%|████▋     | 15/32 [00:03&lt;00:04,  3.94it/s]
 50%|█████     | 16/32 [00:04&lt;00:04,  3.95it/s]
 53%|█████▎    | 17/32 [00:04&lt;00:03,  3.96it/s]
 56%|█████▋    | 18/32 [00:04&lt;00:03,  3.95it/s]
 59%|█████▉    | 19/32 [00:04&lt;00:03,  3.99it/s]
 62%|██████▎   | 20/32 [00:05&lt;00:03,  3.98it/s]
 66%|██████▌   | 21/32 [00:05&lt;00:02,  3.98it/s]
 69%|██████▉   | 22/32 [00:05&lt;00:02,  3.97it/s]
 72%|███████▏  | 23/32 [00:05&lt;00:02,  3.98it/s]
 75%|███████▌  | 24/32 [00:06&lt;00:02,  3.96it/s]
 78%|███████▊  | 25/32 [00:06&lt;00:01,  3.97it/s]
 81%|████████▏ | 26/32 [00:06&lt;00:01,  3.98it/s]
 84%|████████▍ | 27/32 [00:06&lt;00:01,  3.98it/s]
 88%|████████▊ | 28/32 [00:07&lt;00:01,  3.94it/s]
 91%|█████████ | 29/32 [00:07&lt;00:00,  3.91it/s]
 94%|█████████▍| 30/32 [00:07&lt;00:00,  3.94it/s]
 97%|█████████▋| 31/32 [00:07&lt;00:00,  3.95it/s]
100%|██████████| 32/32 [00:07&lt;00:00,  4.06it/s]
</pre></div>
</div>
</section>
<section id="iterating-again-to-compute-the-improved-ece">
<h2>6. Iterating Again to Compute the Improved ECE<a class="headerlink" href="#iterating-again-to-compute-the-improved-ece" title="Permalink to this heading">¶</a></h2>
<p>We can directly use the scaler as a calibrated model.</p>
<p>Note that you will need to first reset the ECE metric to avoid mixing the scores of
the previous and current iterations.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Reset the ECE</span>
<span class="n">ece</span><span class="o">.</span><span class="n">reset</span><span class="p">()</span>

<span class="c1"># Iterate on the test dataloader</span>
<span class="k">for</span> <span class="n">sample</span><span class="p">,</span> <span class="n">target</span> <span class="ow">in</span> <span class="n">test_dataloader</span><span class="p">:</span>
    <span class="n">logits</span> <span class="o">=</span> <span class="n">scaled_model</span><span class="p">(</span><span class="n">sample</span><span class="p">)</span>
    <span class="n">probs</span> <span class="o">=</span> <span class="n">logits</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">ece</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">probs</span><span class="p">,</span> <span class="n">target</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;ECE after scaling - </span><span class="si">{</span><span class="n">ece</span><span class="o">.</span><span class="n">compute</span><span class="p">()</span><span class="si">:</span><span class="s2">.3%</span><span class="si">}</span><span class="s2">.&quot;</span><span class="p">)</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>ECE after scaling - 4.366%.
</pre></div>
</div>
<p>We finally compute and plot the scaled top-label calibration figure. We see
that the model is now better calibrated.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">ece</span><span class="o">.</span><span class="n">plot</span><span class="p">()</span>
<span class="n">fig</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
<img src="../_images/sphx_glr_tutorial_scaler_002.png" srcset="../_images/sphx_glr_tutorial_scaler_002.png" alt="Reliability Diagram" class = "sphx-glr-single-img"/><p>The top-label calibration should be improved.</p>
</section>
<section id="notes">
<h2>Notes<a class="headerlink" href="#notes" title="Permalink to this heading">¶</a></h2>
<p>Temperature scaling is very efficient when the calibration set is representative of the test set.
In this case, we say that the calibration and test set are drawn from the same distribution.
However, this may not hold true in real-world cases where dataset shift could happen.</p>
</section>
<section id="references">
<h2>References<a class="headerlink" href="#references" title="Permalink to this heading">¶</a></h2>
<ul class="simple">
<li><p><strong>Expected Calibration Error:</strong> Naeini, M. P., Cooper, G. F., &amp; Hauskrecht, M. (2015). Obtaining Well Calibrated Probabilities Using Bayesian Binning. In <a class="reference external" href="https://arxiv.org/pdf/1411.0160.pdf">AAAI 2015</a>.</p></li>
<li><p><strong>Temperature Scaling:</strong> Guo, C., Pleiss, G., Sun, Y., &amp; Weinberger, K. Q. (2017). On calibration of modern neural networks. In <a class="reference external" href="https://arxiv.org/pdf/1706.04599.pdf">ICML 2017</a>.</p></li>
</ul>
<p class="sphx-glr-timing"><strong>Total running time of the script:</strong> (0 minutes 30.246 seconds)</p>
<div class="sphx-glr-footer sphx-glr-footer-example docutils container" id="sphx-glr-download-auto-tutorials-tutorial-scaler-py">
<div class="sphx-glr-download sphx-glr-download-jupyter docutils container">
<p><a class="reference download internal" download="" href="../_downloads/35097fc86b1c61efee915836b2ab44fc/tutorial_scaler.ipynb"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Jupyter</span> <span class="pre">notebook:</span> <span class="pre">tutorial_scaler.ipynb</span></code></a></p>
</div>
<div class="sphx-glr-download sphx-glr-download-python docutils container">
<p><a class="reference download internal" download="" href="../_downloads/1be01891b8f2e6a7bd1a0bb5e68c5f96/tutorial_scaler.py"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Python</span> <span class="pre">source</span> <span class="pre">code:</span> <span class="pre">tutorial_scaler.py</span></code></a></p>
</div>
<div class="sphx-glr-download sphx-glr-download-zip docutils container">
<p><a class="reference download internal" download="" href="../_downloads/91ddd48c094a02ba08462f62f0ce47d8/tutorial_scaler.zip"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">zipped:</span> <span class="pre">tutorial_scaler.zip</span></code></a></p>
</div>
</div>
<p class="sphx-glr-signature"><a class="reference external" href="https://sphinx-gallery.github.io">Gallery generated by Sphinx-Gallery</a></p>
</section>
</section>


              </article>
              
            </div>
            <footer>
  
  <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
    
    <a href="tutorial_mc_dropout.html" class="btn btn-neutral float-right" title="Training a LeNet with Monte-Carlo Dropout" accesskey="n"
      rel="next">Next <img src="../_static/images/chevron-right-teal.svg"
        class="next-page"></a>
    
    
    <a href="index.html" class="btn btn-neutral" title="Tutorials" accesskey="p"
      rel="prev"><img src="../_static/images/chevron-right-teal.svg" class="previous-page"> Previous</a>
    
  </div>
  

  <hr>

  <div role="contentinfo">
    <p>
      &copy; Copyright 2024, Adrien Lafage and Olivier Laurent.

    </p>
  </div>
  
  <div>
    Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a
      href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the
      Docs</a>.
  </div>
   

</footer>
          </div>
        </div>

        <div class="pytorch-content-right" id="pytorch-content-right">
          <div class="pytorch-right-menu" id="pytorch-right-menu">
            <div class="pytorch-side-scroll" id="pytorch-side-scroll-right">
              <ul>
<li><a class="reference internal" href="#">Improve Top-label Calibration with Temperature Scaling</a><ul>
<li><a class="reference internal" href="#loading-the-utilities">1. Loading the Utilities</a></li>
<li><a class="reference internal" href="#loading-a-model-from-torchuncertainty-s-hf">2. Loading a model from TorchUncertainty’s HF</a></li>
<li><a class="reference internal" href="#setting-up-the-datamodule-and-dataloaders">3. Setting up the Datamodule and Dataloaders</a></li>
<li><a class="reference internal" href="#iterating-on-the-dataloader-and-computing-the-ece">4. Iterating on the Dataloader and Computing the ECE</a></li>
<li><a class="reference internal" href="#fitting-the-scaler-to-improve-the-calibration">5. Fitting the Scaler to Improve the Calibration</a></li>
<li><a class="reference internal" href="#iterating-again-to-compute-the-improved-ece">6. Iterating Again to Compute the Improved ECE</a></li>
<li><a class="reference internal" href="#notes">Notes</a></li>
<li><a class="reference internal" href="#references">References</a></li>
</ul>
</li>
</ul>

            </div>
          </div>
        </div>
    </section>
  </div>

  


  

  
  <script type="text/javascript" id="documentation_options" data-url_root="../"
    src="../_static/documentation_options.js"></script>
  <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
  <script src="../_static/jquery.js"></script>
  <script src="../_static/underscore.js"></script>
  <script src="../_static/_sphinx_javascript_frameworks_compat.js"></script>
  <script src="../_static/doctools.js"></script>
  <script src="../_static/sphinx_highlight.js"></script>
  <script src="../_static/clipboard.min.js"></script>
  <script src="../_static/copybutton.js"></script>
  

  

  <script type="text/javascript" src="../_static/js/vendor/popper.min.js"></script>
  <script type="text/javascript" src="../_static/js/vendor/bootstrap.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/list.js/1.5.0/list.min.js"></script>
  <script type="text/javascript" src="../_static/js/theme.js"></script>

  <script type="text/javascript">
    jQuery(function () {
      SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

  <!-- Begin Footer -->

  <div class="container-fluid docs-tutorials-resources" id="docs-tutorials-resources">
  </div>

  <!-- End Footer -->

  <!-- Begin Mobile Menu -->

  <div class="mobile-main-menu">
    <div class="container-fluid">
      <div class="container">
        <div class="mobile-main-menu-header-container">
          <a class="header-logo" href="https://torch-uncertainty.github.io/" aria-label="OpenMMLab"></a>
          <a class="main-menu-close-button" href="#" data-behavior="close-mobile-menu"></a>
        </div>
      </div>
    </div>

    <div class="mobile-main-menu-links-container">
      <div class="main-menu">
        <ul>
          <li>
            <a href="https://github.com/ENSTA-U2IS-AI/torch-uncertainty" target="_blank">GitHub</a>
          </li>
      </div>
    </div>
  </div>

  <!-- End Mobile Menu -->

  <script type="text/javascript" src="../_static/js/vendor/anchor.min.js"></script>

  <script type="text/javascript">
    $(document).ready(function () {
      mobileMenu.bind();
      mobileTOC.bind();
      pytorchAnchors.bind();
      sideMenus.bind();
      scrollToAnchor.bind();
      highlightNavigation.bind();
      mainMenuDropdown.bind();
      filterTags.bind();

      // Add class to links that have code blocks, since we cannot create links in code blocks
      $("article.pytorch-article a span.pre").each(function (e) {
        $(this).closest("a").addClass("has-code");
      });
    })
  </script>
</body>

</html>