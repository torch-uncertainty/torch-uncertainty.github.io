{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# For tips on running notebooks in Google Colab, see\n# https://pytorch.org/tutorials/beginner/colab\n%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Training a LeNet with Monte-Carlo Dropout\n\nIn this tutorial, we will train a LeNet classifier on the MNIST dataset using Monte-Carlo Dropout (MC Dropout), a computationally efficient Bayesian approximation method. To estimate the predictive mean and uncertainty (variance), we perform multiple forward passes through the network with dropout layers enabled in ``train`` mode.\n\nFor more information on Monte-Carlo Dropout, we refer the reader to the following resources:\n\n- Dropout as a Bayesian Approximation: Representing Model Uncertainty in Deep Learning [ICML 2016](https://browse.arxiv.org/pdf/1506.02142.pdf)\n- What Uncertainties Do We Need in Bayesian Deep Learning for Computer Vision? [NeurIPS 2017](https://browse.arxiv.org/pdf/1703.04977.pdf)\n\n## Training a LeNet with MC Dropout using TorchUncertainty models and PyTorch Lightning\n\nIn this part, we train a LeNet with dropout layers, based on the model and routines already implemented in TU.\n\n### 1. Loading the utilities\n\nFirst, we have to load the following utilities from TorchUncertainty:\n\n- the TUTrainer from TorchUncertainty utils\n- the datamodule handling dataloaders: MNISTDataModule from torch_uncertainty.datamodules\n- the model: lenet from torch_uncertainty.models\n- the MC Dropout wrapper: mc_dropout, from torch_uncertainty.models.wrappers\n- the classification training & evaluation routine in the torch_uncertainty.routines\n- an optimization recipe in the torch_uncertainty.optim_recipes module.\n\nWe also need import the neural network utils within `torch.nn`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n\nfrom torch_uncertainty import TUTrainer\nfrom torch import nn\n\nfrom torch_uncertainty.datamodules import MNISTDataModule\nfrom torch_uncertainty.models.lenet import lenet\nfrom torch_uncertainty.models import mc_dropout\nfrom torch_uncertainty.optim_recipes import optim_cifar10_resnet18\nfrom torch_uncertainty.routines import ClassificationRoutine"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2. Defining the Model and the Trainer\n\nIn the following, we first create the trainer and instantiate \nthe datamodule that handles the MNIST dataset,\ndataloaders and transforms. We create the model using the\nblueprint from torch_uncertainty.models and we wrap it into an mc_dropout.\nTo use the mc_dropout wrapper, **make sure that you use dropout modules** and\nnot functionals. Moreover, **they have to be** instantiated in the __init__ method.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "trainer = TUTrainer(accelerator=\"cpu\", max_epochs=2, enable_progress_bar=False)\n\n# datamodule\nroot = Path(\"data\")\ndatamodule = MNISTDataModule(root=root, batch_size=128)\n\n\nmodel = lenet(\n    in_channels=datamodule.num_channels,\n    num_classes=datamodule.num_classes,\n    dropout_rate=0.4,\n)\n\nmc_model = mc_dropout(model, num_estimators=16, last_layer=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3. The Loss and the Training Routine\nThis is a classification problem, and we use CrossEntropyLoss as the (negative-log-)likelihood.\nWe define the training routine using the classification training routine from\ntorch_uncertainty.routines. We provide the number of classes\nthe optimization recipe and tell the routine that our model is an ensemble at evaluation time.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "routine = ClassificationRoutine(\n    num_classes=datamodule.num_classes,\n    model=mc_model,\n    loss=nn.CrossEntropyLoss(),\n    optim_recipe=optim_cifar10_resnet18(mc_model),\n    is_ensemble=True,\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4. Gathering Everything and Training the Model\n\nWe can now train the model using the trainer. We pass the routine and the datamodule\nto the fit and test methods of the trainer. It will automatically evaluate some uncertainty\nmetrics that you will find in the table below.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "trainer.fit(model=routine, datamodule=datamodule)\nresults = trainer.test(model=routine, datamodule=datamodule)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 5. Testing the Model\nNow that the model is trained, let's test it on MNIST. Don't forget to call\n.eval() to enable dropout at evaluation and get multiple (here 16) predictions.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\nimport numpy as np\nimport torch\nimport torchvision\n\n\ndef imshow(img):\n    npimg = img.numpy()\n    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n    plt.axis(\"off\")\n    plt.tight_layout()\n    plt.show()\n\n\ndataiter = iter(datamodule.val_dataloader())\nimages, labels = next(dataiter)\n\n# print images\nimshow(torchvision.utils.make_grid(images[:6, ...], padding=0))\nprint(\"Ground truth labels: \", \" \".join(f\"{labels[j]}\" for j in range(6)))\n\nroutine.eval()\nlogits = routine(images).reshape(16, 128, 10)\n\nprobs = torch.nn.functional.softmax(logits, dim=-1)\n\n\nfor j in range(6):\n    values, predicted = torch.max(probs[:, j], 1)\n    print(\n        f\"MC-Dropout predictions for the image {j+1}: \",\n        \" \".join([str(image_id.item()) for image_id in predicted]),\n    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Most of the time, we see that there is some disagreement between the samples of the dropout\napproximation of the posterior distribution.\n\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}