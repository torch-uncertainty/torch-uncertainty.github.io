{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# For tips on running notebooks in Google Colab, see\n# https://pytorch.org/tutorials/beginner/colab\n%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Training a LeNet for Image Classification with TorchUncertainty\n\nIn this tutorial, we will train a LeNet classifier on the MNIST dataset using TorchUncertainty.\nYou will discover two of the core tools from TorchUncertainty, namely\n\n- the routine: a model wrapper, which handles the training and evaluation logics, here for classification\n- the datamodules: python classes, which provide the dataloaders used by the routine\n\n\n## 1. Loading the utilities\n\nFirst, we have to load the following utilities from TorchUncertainty:\n\n- the TUTrainer which mostly handles the link with the hardware (accelerators, precision, etc)\n- the classification training & evaluation routine from torch_uncertainty.routines\n- the datamodule handling dataloaders: MNISTDataModule from torch_uncertainty.datamodules\n- the model: lenet from torch_uncertainty.models\n- an optimization recipe in the torch_uncertainty.optim_recipes module.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n\nfrom torch import nn\n\nfrom torch_uncertainty import TUTrainer\nfrom torch_uncertainty.datamodules import MNISTDataModule\nfrom torch_uncertainty.models.classification.lenet import lenet\nfrom torch_uncertainty.optim_recipes import optim_cifar10_resnet18\nfrom torch_uncertainty.routines import ClassificationRoutine"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Creating the Trainer and the DataModule\n\nIn the following, we first create the trainer and instantiate the datamodule that handles the MNIST dataset,\ndataloaders and transforms.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "trainer = TUTrainer(accelerator=\"gpu\", devices=1, max_epochs=2, enable_progress_bar=False)\n\n# datamodule providing the dataloaders to the trainer\nroot = Path(\"data\")\ndatamodule = MNISTDataModule(root=root, batch_size=128)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Instantiating the Model\n\nWe create the model easily using the blueprint from torch_uncertainty.models.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "model = lenet(\n    in_channels=datamodule.num_channels,\n    num_classes=datamodule.num_classes,\n    dropout_rate=0.4,\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. The Loss and the Routine\n\nThis is a classification problem, and we use CrossEntropyLoss as the (negative-log-)likelihood.\nWe define the training routine using the classification routine from torch_uncertainty.routines.\nWe provide the number of classes, the model, the optimization recipe, the loss, and tell the routine\nthat our model is an ensemble at evaluation time with the `is_ensemble` flag.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "routine = ClassificationRoutine(\n    num_classes=datamodule.num_classes,\n    model=model,\n    loss=nn.CrossEntropyLoss(),\n    optim_recipe=optim_cifar10_resnet18(model),\n    is_ensemble=True,\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Gathering Everything and Training the Model\n\nWe can now train the model using the trainer. We pass the routine and the datamodule\nto the fit and test methods of the trainer. It will automatically evaluate uncertainty\nmetrics that you will find in the table below.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "trainer.fit(model=routine, datamodule=datamodule)\nresults = trainer.test(model=routine, datamodule=datamodule)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Evaluating the Model\n\nNow that the model is trained, let's test it on MNIST.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\nimport numpy as np\nimport torch\nimport torchvision\n\n\ndef imshow(img) -> None:\n    npimg = img.numpy()\n    npimg = npimg * 0.3081 + 0.1307  # unnormalize\n    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n    plt.axis(\"off\")\n    plt.tight_layout()\n    plt.show()\n\n\nimages, labels = next(iter(datamodule.val_dataloader()))\n\n# print images\nimshow(torchvision.utils.make_grid(images[:6, ...], padding=0))\nprint(\"Ground truth labels: \", \" \".join(f\"{labels[j]}\" for j in range(6)))\n\nroutine.eval()\nlogits = routine(images)\n\nprobs = torch.nn.functional.softmax(logits, dim=-1)\n\nvalues, predicted = torch.max(probs, 1)\nprint(\n    \"LeNet predictions for the first 6 images: \",\n    \" \".join([str(image_id.item()) for image_id in predicted[:6]]),\n)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}