
.. DO NOT EDIT.
.. THIS FILE WAS AUTOMATICALLY GENERATED BY SPHINX-GALLERY.
.. TO MAKE CHANGES, EDIT THE SOURCE PYTHON FILE:
.. "auto_tutorials/Post_Hoc_Methods/tutorial_conformal.py"
.. LINE NUMBERS ARE GIVEN BELOW.

.. only:: html

    .. note::
        :class: sphx-glr-download-link-note

        :ref:`Go to the end <sphx_glr_download_auto_tutorials_Post_Hoc_Methods_tutorial_conformal.py>`
        to download the full example code.

.. rst-class:: sphx-glr-example-title

.. _sphx_glr_auto_tutorials_Post_Hoc_Methods_tutorial_conformal.py:


Conformal Prediction on CIFAR-10 with TorchUncertainty
======================================================

We evaluate the model's performance both before and after applying different conformal predictors (THR, APS, RAPS), and visualize how conformal prediction estimates the prediction sets.

We use the pretrained ResNet models we provide on Hugging Face.

.. GENERATED FROM PYTHON SOURCE LINES 12-23

.. code-block:: Python

    import matplotlib.pyplot as plt
    import numpy as np
    import torch
    from huggingface_hub import hf_hub_download

    from torch_uncertainty import TUTrainer
    from torch_uncertainty.datamodules import CIFAR10DataModule
    from torch_uncertainty.models.classification.resnet import resnet
    from torch_uncertainty.post_processing import ConformalClsAPS, ConformalClsRAPS, ConformalClsTHR
    from torch_uncertainty.routines import ClassificationRoutine








.. GENERATED FROM PYTHON SOURCE LINES 24-28

1. Load pretrained model from Hugging Face repository
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

We use a ResNet18 model trained on CIFAR-10, provided by the TorchUncertainty team

.. GENERATED FROM PYTHON SOURCE LINES 28-35

.. code-block:: Python


    ckpt_path = hf_hub_download(repo_id="torch-uncertainty/resnet18_c10", filename="resnet18_c10.ckpt")
    model = resnet(in_channels=3, num_classes=10, arch=18, conv_bias=False, style="cifar")
    ckpt = torch.load(ckpt_path, weights_only=True)
    model.load_state_dict(ckpt)
    model = model.cuda().eval()








.. GENERATED FROM PYTHON SOURCE LINES 36-42

2. Load CIFAR-10 Dataset & Define Dataloaders
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

We set eval_ood to True to evaluate the performance of Conformal scores for detecting out-of-distribution
samples. In this case, since we use a model trained on the full training set, we use the test set to as calibration
set for the Conformal methods and for its evaluation. This is not a proper way to evaluate the coverage.

.. GENERATED FROM PYTHON SOURCE LINES 42-56

.. code-block:: Python


    BATCH_SIZE = 128

    datamodule = CIFAR10DataModule(
        root="./data",
        batch_size=BATCH_SIZE,
        num_workers=8,
        eval_ood=True,
        postprocess_set="test",
    )
    datamodule.prepare_data()
    datamodule.setup()






.. rst-class:: sphx-glr-script-out

 .. code-block:: none

      0%|          | 0.00/170M [00:00<?, ?B/s]      0%|          | 65.5k/170M [00:00<06:55, 410kB/s]      0%|          | 229k/170M [00:00<03:40, 774kB/s]       0%|          | 623k/170M [00:00<01:35, 1.78MB/s]      1%|          | 983k/170M [00:00<01:17, 2.18MB/s]      1%|          | 2.06M/170M [00:00<00:36, 4.56MB/s]      2%|▏         | 3.11M/170M [00:00<00:28, 5.82MB/s]      4%|▎         | 6.19M/170M [00:00<00:13, 12.3MB/s]      5%|▌         | 9.21M/170M [00:01<00:10, 16.0MB/s]      8%|▊         | 13.9M/170M [00:01<00:06, 24.2MB/s]     11%|█         | 18.4M/170M [00:01<00:05, 26.5MB/s]     14%|█▎        | 23.2M/170M [00:01<00:04, 31.8MB/s]     16%|█▋        | 28.0M/170M [00:01<00:04, 31.7MB/s]     19%|█▉        | 32.7M/170M [00:01<00:03, 35.6MB/s]     22%|██▏       | 37.5M/170M [00:01<00:03, 38.6MB/s]     24%|██▍       | 41.5M/170M [00:01<00:03, 35.0MB/s]     27%|██▋       | 46.0M/170M [00:01<00:03, 37.7MB/s]     29%|██▉       | 50.2M/170M [00:02<00:03, 34.6MB/s]     32%|███▏      | 54.9M/170M [00:02<00:03, 37.7MB/s]     35%|███▍      | 59.5M/170M [00:02<00:02, 39.9MB/s]     37%|███▋      | 63.6M/170M [00:02<00:03, 35.5MB/s]     40%|████      | 68.6M/170M [00:02<00:02, 39.1MB/s]     43%|████▎     | 72.7M/170M [00:02<00:02, 35.4MB/s]     45%|████▌     | 77.2M/170M [00:02<00:02, 38.0MB/s]     48%|████▊     | 81.9M/170M [00:02<00:02, 35.4MB/s]     51%|█████     | 86.6M/170M [00:03<00:02, 38.2MB/s]     54%|█████▎    | 91.3M/170M [00:03<00:01, 40.5MB/s]     56%|█████▌    | 95.5M/170M [00:03<00:02, 36.6MB/s]     59%|█████▊    | 100M/170M [00:03<00:01, 38.8MB/s]      61%|██████    | 104M/170M [00:03<00:01, 35.0MB/s]     64%|██████▍   | 109M/170M [00:03<00:01, 37.8MB/s]     66%|██████▋   | 113M/170M [00:03<00:01, 39.4MB/s]     69%|██████▉   | 117M/170M [00:03<00:01, 35.8MB/s]     71%|███████   | 121M/170M [00:04<00:01, 36.0MB/s]     73%|███████▎  | 125M/170M [00:04<00:01, 36.1MB/s]     75%|███████▌  | 128M/170M [00:04<00:01, 34.5MB/s]     77%|███████▋  | 132M/170M [00:04<00:01, 35.0MB/s]     80%|███████▉  | 136M/170M [00:04<00:00, 35.0MB/s]     82%|████████▏ | 139M/170M [00:04<00:00, 35.1MB/s]     84%|████████▎ | 143M/170M [00:04<00:00, 35.3MB/s]     86%|████████▌ | 146M/170M [00:04<00:00, 34.1MB/s]     88%|████████▊ | 150M/170M [00:04<00:00, 34.8MB/s]     90%|█████████ | 154M/170M [00:04<00:00, 34.3MB/s]     92%|█████████▏| 157M/170M [00:05<00:00, 34.7MB/s]     94%|█████████▍| 161M/170M [00:05<00:00, 33.3MB/s]     96%|█████████▋| 164M/170M [00:05<00:00, 33.6MB/s]     98%|█████████▊| 168M/170M [00:05<00:00, 33.9MB/s]    100%|██████████| 170M/170M [00:05<00:00, 31.2MB/s]
      0%|          | 0.00/64.3M [00:00<?, ?B/s]      0%|          | 32.8k/64.3M [00:00<04:34, 234kB/s]      0%|          | 65.5k/64.3M [00:00<04:36, 233kB/s]      0%|          | 98.3k/64.3M [00:00<04:35, 233kB/s]      0%|          | 131k/64.3M [00:00<04:35, 233kB/s]       0%|          | 197k/64.3M [00:00<03:22, 317kB/s]      0%|          | 295k/64.3M [00:00<02:23, 446kB/s]      1%|          | 426k/64.3M [00:00<01:45, 604kB/s]      1%|          | 590k/64.3M [00:01<01:21, 782kB/s]      1%|          | 786k/64.3M [00:01<01:05, 974kB/s]      2%|▏         | 1.08M/64.3M [00:01<00:47, 1.32MB/s]      2%|▏         | 1.44M/64.3M [00:01<00:36, 1.70MB/s]      3%|▎         | 1.93M/64.3M [00:01<00:27, 2.24MB/s]      4%|▍         | 2.56M/64.3M [00:01<00:21, 2.90MB/s]      5%|▌         | 3.38M/64.3M [00:01<00:16, 3.78MB/s]      7%|▋         | 4.39M/64.3M [00:02<00:12, 4.80MB/s]      9%|▉         | 5.67M/64.3M [00:02<00:09, 6.10MB/s]     11%|█         | 7.21M/64.3M [00:02<00:07, 7.55MB/s]     14%|█▍        | 9.21M/64.3M [00:02<00:05, 9.51MB/s]     18%|█▊        | 11.6M/64.3M [00:02<00:04, 11.7MB/s]     23%|██▎       | 14.5M/64.3M [00:02<00:03, 14.4MB/s]     25%|██▍       | 15.9M/64.3M [00:02<00:03, 12.9MB/s]     29%|██▊       | 18.4M/64.3M [00:03<00:03, 14.5MB/s]     32%|███▏      | 20.5M/64.3M [00:03<00:02, 14.6MB/s]     36%|███▌      | 23.0M/64.3M [00:03<00:02, 15.5MB/s]     40%|███▉      | 25.6M/64.3M [00:03<00:02, 16.4MB/s]     44%|████▎     | 28.1M/64.3M [00:03<00:02, 16.8MB/s]     48%|████▊     | 30.7M/64.3M [00:03<00:01, 17.3MB/s]     52%|█████▏    | 33.4M/64.3M [00:03<00:01, 17.8MB/s]     56%|█████▌    | 35.9M/64.3M [00:04<00:01, 17.9MB/s]     60%|██████    | 38.6M/64.3M [00:04<00:01, 18.2MB/s]     64%|██████▍   | 41.3M/64.3M [00:04<00:01, 18.5MB/s]     69%|██████▊   | 44.1M/64.3M [00:04<00:01, 18.8MB/s]     73%|███████▎  | 46.8M/64.3M [00:04<00:00, 19.0MB/s]     77%|███████▋  | 49.6M/64.3M [00:04<00:00, 19.3MB/s]     82%|████████▏ | 52.4M/64.3M [00:04<00:00, 19.5MB/s]     86%|████████▌ | 55.2M/64.3M [00:05<00:00, 19.6MB/s]     90%|█████████ | 58.0M/64.3M [00:05<00:00, 19.6MB/s]     95%|█████████▍| 60.9M/64.3M [00:05<00:00, 19.8MB/s]     99%|█████████▉| 63.7M/64.3M [00:05<00:00, 19.9MB/s]    100%|██████████| 64.3M/64.3M [00:05<00:00, 11.7MB/s]




.. GENERATED FROM PYTHON SOURCE LINES 57-59

3. Define the Lightning Trainer
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

.. GENERATED FROM PYTHON SOURCE LINES 59-63

.. code-block:: Python


    trainer = TUTrainer(accelerator="gpu", devices=1, max_epochs=5, enable_progress_bar=False)









.. GENERATED FROM PYTHON SOURCE LINES 64-66

4. Function to Visualize the Prediction Sets
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

.. GENERATED FROM PYTHON SOURCE LINES 66-87

.. code-block:: Python



    def visualize_prediction_sets(inputs, labels, confidence_scores, classes, num_examples=5) -> None:
        _, axs = plt.subplots(2, num_examples, figsize=(15, 5))
        for i in range(num_examples):
            ax = axs[0, i]
            img = np.clip(
                inputs[i].permute(1, 2, 0).cpu().numpy() * datamodule.std + datamodule.mean, 0, 1
            )
            ax.imshow(img)
            ax.set_title(f"True: {classes[labels[i]]}")
            ax.axis("off")
            ax = axs[1, i]
            for j in range(len(classes)):
                ax.barh(classes[j], confidence_scores[i, j], color="blue")
            ax.set_xlim(0, 1)
            ax.set_xlabel("Confidence Score")
        plt.tight_layout()
        plt.show()









.. GENERATED FROM PYTHON SOURCE LINES 88-92

5. Estimate Prediction Sets with ConformalClsTHR
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Using alpha=0.01, we aim for a 1% error rate.

.. GENERATED FROM PYTHON SOURCE LINES 92-106

.. code-block:: Python


    print("[Phase 2]: ConformalClsTHR calibration")
    conformal_model = ConformalClsTHR(alpha=0.01, device="cuda")

    routine_thr = ClassificationRoutine(
        num_classes=10,
        model=model,
        loss=None,  # No loss needed for evaluation
        eval_ood=True,
        post_processing=conformal_model,
        ood_criterion="post_processing",
    )
    perf_thr = trainer.test(routine_thr, datamodule=datamodule)





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    [Phase 2]: ConformalClsTHR calibration
      0%|          | 0/79 [00:00<?, ?it/s]      1%|▏         | 1/79 [00:00<00:20,  3.81it/s]     10%|█         | 8/79 [00:00<00:02, 26.21it/s]     18%|█▊        | 14/79 [00:00<00:01, 36.58it/s]     25%|██▌       | 20/79 [00:00<00:01, 43.50it/s]     33%|███▎      | 26/79 [00:00<00:01, 48.17it/s]     41%|████      | 32/79 [00:00<00:00, 51.33it/s]     48%|████▊     | 38/79 [00:00<00:00, 53.47it/s]     56%|█████▌    | 44/79 [00:00<00:00, 54.94it/s]     63%|██████▎   | 50/79 [00:01<00:00, 55.91it/s]     71%|███████   | 56/79 [00:01<00:00, 56.67it/s]     78%|███████▊  | 62/79 [00:01<00:00, 57.16it/s]     86%|████████▌ | 68/79 [00:01<00:00, 57.52it/s]     94%|█████████▎| 74/79 [00:01<00:00, 57.76it/s]    100%|██████████| 79/79 [00:01<00:00, 49.37it/s]
    ┏━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓
    ┃ Test metric  ┃      Classification       ┃
    ┡━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩
    │     Acc      │          93.380%          │
    │    Brier     │          0.10812          │
    │   Entropy    │          0.08849          │
    │     NLL      │          0.26405          │
    └──────────────┴───────────────────────────┘
    ┏━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓
    ┃ Test metric  ┃        Calibration        ┃
    ┡━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩
    │     ECE      │          3.537%           │
    │     aECE     │          3.499%           │
    └──────────────┴───────────────────────────┘
    ┏━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓
    ┃ Test metric  ┃       OOD Detection       ┃
    ┡━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩
    │     AUPR     │          86.587%          │
    │    AUROC     │          79.260%          │
    │   Entropy    │          0.08849          │
    │    FPR95     │         100.000%          │
    └──────────────┴───────────────────────────┘
    ┏━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓
    ┃ Test metric  ┃ Selective Classification  ┃
    ┡━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩
    │    AUGRC     │          0.779%           │
    │     AURC     │          0.959%           │
    │  Cov@5Risk   │          96.510%          │
    │  Risk@80Cov  │          1.200%           │
    └──────────────┴───────────────────────────┘
    ┏━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓
    ┃ Test metric  ┃      Post-Processing      ┃
    ┡━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩
    │ CoverageRate │          0.99000          │
    │   SetSize    │          1.52340          │
    └──────────────┴───────────────────────────┘
    ┏━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓
    ┃ Test metric  ┃        Complexity         ┃
    ┡━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩
    │    flops     │         142.19 G          │
    │    params    │          11.17 M          │
    └──────────────┴───────────────────────────┘




.. GENERATED FROM PYTHON SOURCE LINES 107-109

6. Visualization of ConformalClsTHR prediction sets
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

.. GENERATED FROM PYTHON SOURCE LINES 109-119

.. code-block:: Python


    inputs, labels = next(iter(datamodule.test_dataloader()[0]))

    conformal_model.cuda()
    confidence_scores = conformal_model.conformal(inputs.cuda())

    classes = datamodule.test.classes

    visualize_prediction_sets(inputs, labels, confidence_scores[:5].cpu(), classes)




.. image-sg:: /auto_tutorials/Post_Hoc_Methods/images/sphx_glr_tutorial_conformal_001.png
   :alt: True: cat, True: ship, True: ship, True: airplane, True: frog
   :srcset: /auto_tutorials/Post_Hoc_Methods/images/sphx_glr_tutorial_conformal_001.png
   :class: sphx-glr-single-img





.. GENERATED FROM PYTHON SOURCE LINES 120-122

7. Estimate Prediction Sets with ConformalClsAPS
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

.. GENERATED FROM PYTHON SOURCE LINES 122-139

.. code-block:: Python


    print("[Phase 3]: ConformalClsAPS calibration")
    conformal_model = ConformalClsAPS(alpha=0.01, device="cuda", enable_ts=False)

    routine_aps = ClassificationRoutine(
        num_classes=10,
        model=model,
        loss=None,  # No loss needed for evaluation
        eval_ood=True,
        post_processing=conformal_model,
        ood_criterion="post_processing",
    )
    perf_aps = trainer.test(routine_aps, datamodule=datamodule)
    conformal_model.cuda()
    confidence_scores = conformal_model.conformal(inputs.cuda())
    visualize_prediction_sets(inputs, labels, confidence_scores[:5].cpu(), classes)




.. image-sg:: /auto_tutorials/Post_Hoc_Methods/images/sphx_glr_tutorial_conformal_002.png
   :alt: True: cat, True: ship, True: ship, True: airplane, True: frog
   :srcset: /auto_tutorials/Post_Hoc_Methods/images/sphx_glr_tutorial_conformal_002.png
   :class: sphx-glr-single-img


.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    [Phase 3]: ConformalClsAPS calibration
    ┏━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓
    ┃ Test metric  ┃      Classification       ┃
    ┡━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩
    │     Acc      │          93.380%          │
    │    Brier     │          0.10812          │
    │   Entropy    │          0.08849          │
    │     NLL      │          0.26405          │
    └──────────────┴───────────────────────────┘
    ┏━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓
    ┃ Test metric  ┃        Calibration        ┃
    ┡━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩
    │     ECE      │          3.536%           │
    │     aECE     │          3.499%           │
    └──────────────┴───────────────────────────┘
    ┏━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓
    ┃ Test metric  ┃       OOD Detection       ┃
    ┡━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩
    │     AUPR     │          84.873%          │
    │    AUROC     │          77.063%          │
    │   Entropy    │          0.08849          │
    │    FPR95     │         100.000%          │
    └──────────────┴───────────────────────────┘
    ┏━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓
    ┃ Test metric  ┃ Selective Classification  ┃
    ┡━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩
    │    AUGRC     │          0.779%           │
    │     AURC     │          0.959%           │
    │  Cov@5Risk   │          96.510%          │
    │  Risk@80Cov  │          1.200%           │
    └──────────────┴───────────────────────────┘
    ┏━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓
    ┃ Test metric  ┃      Post-Processing      ┃
    ┡━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩
    │ CoverageRate │          0.98990          │
    │   SetSize    │          1.72780          │
    └──────────────┴───────────────────────────┘
    ┏━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓
    ┃ Test metric  ┃        Complexity         ┃
    ┡━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩
    │    flops     │         142.19 G          │
    │    params    │          11.17 M          │
    └──────────────┴───────────────────────────┘




.. GENERATED FROM PYTHON SOURCE LINES 140-142

8. Estimate Prediction Sets with ConformalClsRAPS
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

.. GENERATED FROM PYTHON SOURCE LINES 142-161

.. code-block:: Python


    print("[Phase 4]: ConformalClsRAPS calibration")
    conformal_model = ConformalClsRAPS(
        alpha=0.01, regularization_rank=3, penalty=0.002, model=model, device="cuda", enable_ts=False
    )

    routine_raps = ClassificationRoutine(
        num_classes=10,
        model=model,
        loss=None,  # No loss needed for evaluation
        eval_ood=True,
        post_processing=conformal_model,
        ood_criterion="post_processing",
    )
    perf_raps = trainer.test(routine_raps, datamodule=datamodule)
    conformal_model.cuda()
    confidence_scores = conformal_model.conformal(inputs.cuda())
    visualize_prediction_sets(inputs, labels, confidence_scores[:5].cpu(), classes)




.. image-sg:: /auto_tutorials/Post_Hoc_Methods/images/sphx_glr_tutorial_conformal_003.png
   :alt: True: cat, True: ship, True: ship, True: airplane, True: frog
   :srcset: /auto_tutorials/Post_Hoc_Methods/images/sphx_glr_tutorial_conformal_003.png
   :class: sphx-glr-single-img


.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    [Phase 4]: ConformalClsRAPS calibration
    ┏━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓
    ┃ Test metric  ┃      Classification       ┃
    ┡━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩
    │     Acc      │          93.380%          │
    │    Brier     │          0.10812          │
    │   Entropy    │          0.08849          │
    │     NLL      │          0.26405          │
    └──────────────┴───────────────────────────┘
    ┏━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓
    ┃ Test metric  ┃        Calibration        ┃
    ┡━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩
    │     ECE      │          3.536%           │
    │     aECE     │          3.499%           │
    └──────────────┴───────────────────────────┘
    ┏━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓
    ┃ Test metric  ┃       OOD Detection       ┃
    ┡━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩
    │     AUPR     │          85.499%          │
    │    AUROC     │          77.486%          │
    │   Entropy    │          0.08849          │
    │    FPR95     │         100.000%          │
    └──────────────┴───────────────────────────┘
    ┏━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓
    ┃ Test metric  ┃ Selective Classification  ┃
    ┡━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩
    │    AUGRC     │          0.779%           │
    │     AURC     │          0.959%           │
    │  Cov@5Risk   │          96.510%          │
    │  Risk@80Cov  │          1.200%           │
    └──────────────┴───────────────────────────┘
    ┏━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓
    ┃ Test metric  ┃      Post-Processing      ┃
    ┡━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩
    │ CoverageRate │          0.99070          │
    │   SetSize    │          1.69950          │
    └──────────────┴───────────────────────────┘
    ┏━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓
    ┃ Test metric  ┃        Complexity         ┃
    ┡━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩
    │    flops     │         142.19 G          │
    │    params    │          11.17 M          │
    └──────────────┴───────────────────────────┘




.. GENERATED FROM PYTHON SOURCE LINES 162-169

Summary
-------

In this tutorial, we explored how to apply conformal prediction to a pretrained ResNet on CIFAR-10.
We evaluated three methods: Thresholding (THR), Adaptive Prediction Sets (APS), and Regularized APS (RAPS).
For each, we calibrated on a validation set, evaluated OOD performance, and visualized prediction sets.
You can explore further by adjusting `alpha`, changing the model, or testing on other datasets.


.. rst-class:: sphx-glr-timing

   **Total running time of the script:** (1 minutes 0.315 seconds)


.. _sphx_glr_download_auto_tutorials_Post_Hoc_Methods_tutorial_conformal.py:

.. only:: html

  .. container:: sphx-glr-footer sphx-glr-footer-example

    .. container:: sphx-glr-download sphx-glr-download-jupyter

      :download:`Download Jupyter notebook: tutorial_conformal.ipynb <tutorial_conformal.ipynb>`

    .. container:: sphx-glr-download sphx-glr-download-python

      :download:`Download Python source code: tutorial_conformal.py <tutorial_conformal.py>`

    .. container:: sphx-glr-download sphx-glr-download-zip

      :download:`Download zipped: tutorial_conformal.zip <tutorial_conformal.zip>`


.. only:: html

 .. rst-class:: sphx-glr-signature

    `Gallery generated by Sphinx-Gallery <https://sphinx-gallery.github.io>`_
